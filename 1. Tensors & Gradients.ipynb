{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ba8c8a3",
   "metadata": {},
   "source": [
    "# 1. PyTorch Basics: Tensors & Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db1a61",
   "metadata": {},
   "source": [
    "이 시리즈의 첫번째 파트에서는 다음과 같은 항목을 다룹니다.\n",
    "\n",
    "* PyTorch Tensor 소개\n",
    "* Tensor 연산 및 gradients\n",
    "* PyTorch와 Numpy 간의 상호 운용성\n",
    "* PyTorch 문서 사이트를 사용하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f374c",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f64f6",
   "metadata": {},
   "source": [
    "파이토치를 시작하기 위해 torch 모듈을 임포트합니다. (설치는 완료되어 있다고 가정하고 진행합니다.)\n",
    "해당 문서는 pytorch 1.7.1 버전을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b5c4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a57bce8",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "- 파이토치는 텐서를 처리하기 위한 라이브러리입니다.\n",
    "- 텐서는 숫자, 벡터, 행렬 또는 n차원 배열입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a1fed",
   "metadata": {},
   "source": [
    "단일 숫자로 텐서를 생성해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849d7eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number\n",
    "t1 = torch.tensor(4.)\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0525443b",
   "metadata": {},
   "source": [
    "4.는 4.0의 줄임말입니다. 파이썬(또는 파이토치)에서 부동 소수점 숫자를 생성하는데 사용됩니다. 텐서의 데이터 타입(dtype) 속성을 통해서 이를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "365f5554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac56e7",
   "metadata": {},
   "source": [
    "조금 더 복잡한 텐서를 만들어 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "536dd882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "t2 = torch.tensor([1., 2, 3, 4])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd698de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matric\n",
    "t3 = torch.tensor([[5., 6],\n",
    "                   [7, 8],\n",
    "                   [9, 10]])\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0269bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11, 12, 13],\n",
       "         [13, 14, 15]],\n",
       "\n",
       "        [[15, 16, 17],\n",
       "         [17, 18, 19]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-dimensional array\n",
    "t4 = torch.tensor([ \n",
    "    [[11, 12, 13],\n",
    "     [13, 14, 15]],\n",
    "    [[15, 16, 17],\n",
    "     [17, 18, 19]]])\n",
    "t4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2152d5",
   "metadata": {},
   "source": [
    "텐서는 여러 차원과 각 차원마다 다른 길이를 가질 수 있습니다. 텐서의 .shape 속성을 사용하여 각 차원의 길이를 검사할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcbaa494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t1)\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19fa650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t2)\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e654a5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t3)\n",
    "t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b0fd250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[11, 12, 13],\n",
      "         [13, 14, 15]],\n",
      "\n",
      "        [[15, 16, 17],\n",
      "         [17, 18, 19]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t4)\n",
    "t4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2dc71f",
   "metadata": {},
   "source": [
    "주의 : 부적절한 모양으로 텐서를 생성하는 것은 불가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1199895",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = torch.tensor([[5., 6, 11],\n",
    "                   [7, 8],\n",
    "                   [9, 10]])\n",
    "t5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca57cdd",
   "metadata": {},
   "source": [
    "행 [5., 6, 11] 및 [7, 8]의 길이가 일치하지 않기 때문에 ValueError가 발생합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b953214",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e0f90",
   "metadata": {},
   "source": [
    "## Tensor operations and gradients\n",
    "\n",
    "- 텐서들에 일반적인 산술 연산을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d039e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서는 다음과 같이 required_grad=True로 생성할 수 있습니다.\n",
    "# torch.autograd는 자동 미분을 위해 연산을 기록합니다.\n",
    "\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "x, w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42fb57a",
   "metadata": {},
   "source": [
    "세 개의 텐서를 만들었습니다. x, w, b는 모두 숫자입니다. w 및 b에는 추가 매개변수 requires_grad 가 True 로 설정되어 있습니다. 우리는 잠시 후에 그것이 무엇을 하는지 볼 것입니다. 이 텐서를 결합하여 새로운 텐서 y를 생성해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ac2f08e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arithmetic operations \n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587450be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y는 값이 3 * 4 + 5 = 17인 텐서입니다. 파이토치를 고유하게 만드는 것은 require_grad 가 True 로 설정된 텐서, \n",
    "즉 w 및 b에 대한 y의 미분들을 자동으로 계산할 수 있다는 것입니다. 파이토치의 이 기능을 autograd(자동 그라디언트)라고 합니다.\n",
    "\n",
    "미분을 계산하기 위해 결과 y에 대해 .backward 메서드를 호출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3b04a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute derivatives\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7425ea2",
   "metadata": {},
   "source": [
    "입력 텐서에 대한 y의 미분은 각 텐서의 .grad 속성에 저장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "206a6139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: 3.0\n",
      "dy/db: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Display gradients\n",
    "print(f'dy/dx: {x.grad}')\n",
    "print(f'dy/dw: {w.grad}')\n",
    "print(f'dy/db: {b.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c234775",
   "metadata": {},
   "source": [
    "예상대로 dy/dw는 x와 동일한 값, 즉 3을 가지며 dy/db는 1의 값을 갖습니다. x에 require_grad가 True로 설정되어 있지 않기 때문에 x.grad는 None입니다.\n",
    "\n",
    "w.grad의 \"grad\"는 미분의 또 다른 용어인 gradient의 약자입니다. gradient라는 용어는 벡터와 행렬을 다룰 때 주로 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42f662",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1164bbc",
   "metadata": {},
   "source": [
    "#### 짤막한 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39904da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27., 27.],\n",
       "        [27., 27.]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "y = x + 2\n",
    "z = y * y * 3\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d79467bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dout/dz: None\n",
      "dout/dy: None\n",
      "dout/dx: tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-2672fe1dd3fd>:4: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  print(f'dout/dz: {z.grad}')\n",
      "<ipython-input-13-2672fe1dd3fd>:5: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  print(f'dout/dy: {y.grad}')\n"
     ]
    }
   ],
   "source": [
    "out = z.mean()\n",
    "out.backward()\n",
    "\n",
    "print(f'dout/dz: {z.grad}')\n",
    "print(f'dout/dy: {y.grad}')\n",
    "print(f'dout/dx: {x.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68bcc1",
   "metadata": {},
   "source": [
    "y와 z는 is_leaf가 False라서 y.grad와 z.grad에 Gradient가 저장되지 않습니다. \n",
    "\n",
    "만약에 is_leaf가 아닌 Tensor에 Gradient가 grad에 저장되게 하고 싶으면, \n",
    "해당 Tensor의 retain_grad()를 호출해서 retains_grad를 True로 설정하고, backward()를 호출하면 grad에 저장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a883abb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dout/dz: tensor([[0.2500, 0.2500],\n",
      "        [0.2500, 0.2500]])\n",
      "dout/dy: tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n",
      "dout/dx: tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "y.retain_grad()\n",
    "z.retain_grad()\n",
    "out = z.mean()\n",
    "out.backward(retain_graph=True)\n",
    "\n",
    "print(f'dout/dz: {z.grad}')\n",
    "print(f'dout/dy: {y.grad}')\n",
    "print(f'dout/dx: {x.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d368cfa",
   "metadata": {},
   "source": [
    "다음 get_tensor_info 함수에서 텐서의 요소들을 살펴볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56158a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: requires_grad(True) is_leaf(True) retains_grad(None) grad_fn(None) grad(tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])) tensor(tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "def get_tensor_info(tensor):\n",
    "    info = []\n",
    "    for name in ['requires_grad', 'is_leaf', 'retains_grad', 'grad_fn', 'grad']:\n",
    "        info.append(f'{name}({getattr(tensor, name, None)})')\n",
    "    info.append(f'tensor({str(tensor)})')\n",
    "    return ' '.join(info)\n",
    "\n",
    "print(f'x: {get_tensor_info(x)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12080621",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b63a474",
   "metadata": {},
   "source": [
    "## Tensor functions\n",
    "\n",
    "산술 연산 외에도 torch 모듈에는 텐서를 생성하고 조작하기 위한 많은 함수들이 포함되어 있습니다. 몇 가지 예를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1121e24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42, 42],\n",
       "        [42, 42],\n",
       "        [42, 42]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor with a fixed value for every element\n",
    "t6 = torch.full((3,2), 42)\n",
    "t6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f190c4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.],\n",
       "        [42., 42.],\n",
       "        [42., 42.],\n",
       "        [42., 42.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate two tensors with compatible shapes\n",
    "t7 = torch.cat((t3, t6))\n",
    "t7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "892c6374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9589, -0.2794],\n",
       "        [ 0.6570,  0.9894],\n",
       "        [ 0.4121, -0.5440],\n",
       "        [-0.9165, -0.9165],\n",
       "        [-0.9165, -0.9165],\n",
       "        [-0.9165, -0.9165]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the sin() of each element\n",
    "t8 = torch.sin(t7)\n",
    "t8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "424e4f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9589, -0.2794],\n",
       "         [ 0.6570,  0.9894]],\n",
       "\n",
       "        [[ 0.4121, -0.5440],\n",
       "         [-0.9165, -0.9165]],\n",
       "\n",
       "        [[-0.9165, -0.9165],\n",
       "         [-0.9165, -0.9165]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the shape of a tensor\n",
    "t9 = t8.reshape(3, 2, 2)\n",
    "t9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576893d3",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72dceaa",
   "metadata": {},
   "source": [
    "## Interoperability with Numpy\n",
    "\n",
    "Numpy는 Python에서 수학 및 과학 컴퓨팅에 사용되는 인기 있는 오픈 소스 라이브러리입니다. 대규모 다차원 배열에서 효율적인 작업을 가능하게 하며 다음을 포함하는 지원 라이브러리의 방대한 에코시스템을 갖추고 있습니다.\n",
    "\n",
    "* 파일 I/O 및 데이터 분석을 위한 Pandas\n",
    "* 플로팅 및 시각화를 위한 Matplotlib\n",
    "* 이미지 및 비디오 처리를 위한 OpenCV\n",
    "\n",
    "Python의 Numpy 및 기타 데이터 과학 라이브러리에 대해 자세히 알아보려면 https://jovian.ai/aakashns/python-numerical-computing-with-numpy 튜토리얼 시리즈를 확인하세요.\n",
    "\n",
    "\n",
    "텐서는 torch.tensor() 생성자를 사용하여 Python list 또는 numpy array로부터 생성할 수 있습니다. 하지만 list와 array는 근본적인 차이가 있어 주의해야합니다.\n",
    "\n",
    "### python list\n",
    "다른 데이터 타입을 포함할 수 있습니다. (예: a = ['hi', 6, 8] )\n",
    "list들 간에 산술연산을 수행할 수 없습니다.\n",
    "list 안에 다양한 크기의 list를 담을 수 있습니다. (예: b = ['j', [1,2,3], 'hello'] )\n",
    "\n",
    "### numpy array\n",
    "같은 데이터 타입만을 포함할 수 있습니다. (예: a = numpy.array([1, 2, 3]) )\n",
    "array 들 간에 산술연산을 수행할 수 있습니다.\n",
    "array 안에 포함된 array 들은 동일한 크기여야 합니다. (b = numpy.array([[1,2],[3,4]]) )\n",
    "\n",
    "Python에서 list 를 만드는 방법과 이를 텐서로 변형하는 방법은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f81bf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, -1], [1, -1]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =[[1., -1], [1, -1]]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd037d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.],\n",
       "        [ 1., -1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at = torch.tensor([[1., -1], [1, -1]])\n",
    "at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b22daec",
   "metadata": {},
   "source": [
    "Numpy에서 배열을 만드는 방법과 이를 텐서로 변형하는 방법은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af786054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[1, 2], [3, 4.]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5b937a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor(np.array([[1, 2], [3, 4]]))\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd2fcf",
   "metadata": {},
   "source": [
    "torch.from_numpy를 사용하여 Numpy 배열을 PyTorch 텐서로 변환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "046cf0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the numpy array to a torch tensor.\n",
    "y = torch.from_numpy(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59185b34",
   "metadata": {},
   "source": [
    "numpy 배열과 torch 텐서의 데이터 유형이 유사한지 확인하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c218e3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a881df6",
   "metadata": {},
   "source": [
    "텐서의 .numpy 메서드를 사용하여 PyTorch 텐서를 Numpy 배열로 변환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6820a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert a torch tensor to a numpy array\n",
    "z = y.numpy()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d86fc",
   "metadata": {},
   "source": [
    "PyTorch와 Numpy간의 상호 운용성은 작업할 대부분의 데이터 세트가 Numpy 배열로 읽고 사전 처리될 가능성이 높기 때문에 필수적입니다.\n",
    "\n",
    "Numpy는 이미 다차원 숫자 데이터 작업을 위한 데이터 구조와 유틸리티를 제공하기 때문에 PyTorch와 같은 라이브러리가 필요한 이유가 궁금할 것입니다. 두 가지 주요 이유가 있습니다.\n",
    "\n",
    "1. Autograd: 텐서 연산의 미분을 자동으로 계산하는 기능은 딥 러닝 모델을 훈련하는 데 필수적입니다.\n",
    "2. GPU 지원: 대규모 데이터 세트 및 대규모 모델로 작업하는 동안 PyTorch 텐서 작업은 GPU(그래픽 처리 장치)를 사용하여 효율적으로 수행할 수 있습니다. 일반적으로 몇 시간이 걸릴 수 있는 계산을 GPU를 사용하면 몇 분 안에 완료할 수 있습니다.\n",
    "\n",
    "이 시리즈에서 PyTorch의 이러한 두 기능을 광범위하게 활용할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b87a2b5",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
