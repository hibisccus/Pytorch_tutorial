{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b34fb534",
   "metadata": {},
   "source": [
    "# Gradient Descent and Linear Regression with PyTorch\n",
    "\n",
    "이 시리즈의 두번째 파트에서는 다음과 같은 항목을 다룹니다.\n",
    "\n",
    "* 선형 회귀 분석 및 경사 하강법 소개\n",
    "* PyTorch 텐서를 사용하여 선형 회귀 모델 구현\n",
    "* 경사 하강 알고리즘을 사용한 선형 회귀 모델 학습\n",
    "* 내장된 PyTorch를 사용하여 경사 하강법 및 선형 회귀 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6253e884",
   "metadata": {},
   "source": [
    "## Introduction to Linear Regression\n",
    "\n",
    "이 파트에서는 기계 학습의 기본 알고리즘 중 하나인 선형 회귀(linear regression)에 대해 설명합니다. 지역의 평균 기온, 강우량, 습도(입력 변수 또는 특징)를 보고 사과와 오렌지(목표 변수)의 작물 수확량을 예측하는 모델을 만들 것입니다. 다음은 훈련 데이터입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382dccbd",
   "metadata": {},
   "source": [
    "![linear-regression-training-data](https://i.imgur.com/6Ujttb4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356fc3ba",
   "metadata": {},
   "source": [
    "선형 회귀 모델에서 각 목표 변수는 입력 변수의 가중치 합(weighted sum)으로 추정되며 편향(bias)이라고 하는 상수로 오프셋됩니다. :\n",
    "\n",
    "yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1 <br>\n",
    "yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
    "\n",
    "시각적으로 사과의 수확량은 온도, 강우량 및 습도의 선형 또는 평면 함수임을 의미합니다.:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abb6e47",
   "metadata": {},
   "source": [
    "![linear-regression-graph](https://i.imgur.com/4DJ9f8X.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc5ba99",
   "metadata": {},
   "source": [
    "선형 회귀의 학습 부분은 훈련 데이터를 사용하여 가중치 'w11, w12,... w23, b1 & b2'의 집합을 파악하여 새로운 데이터에 대한 정확한 예측을 수행하는 것입니다. 학습된 가중치는 해당 지역의 평균 온도, 강우량 및 습도를 사용하여 새 지역에서 사과와 오렌지의 수확량을 예측하는 데 사용됩니다.\n",
    "\n",
    "경사하강법(gradient descent)이라는 최적화 기술을 사용하여 더 나은 예측을 위해 가중치를 약간 여러 번 조정하여 모델을 훈련합니다. Numpy와 PyTorch를 가져오는 것부터 시작하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bcaffa",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "우리는 'inputs'과 'targets'라는 두 개의 행렬을 사용하여 훈련 데이터를 나타낼 수 있으며, 각각 관찰당 하나의 행과 변수당 하나의 열이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fcdd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65d4f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43],\n",
    "                  [91, 88, 64],\n",
    "                  [87, 134, 58],\n",
    "                  [102, 43, 37],\n",
    "                  [69, 96, 70]], dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70],\n",
    "                   [81, 101],\n",
    "                   [119, 133],\n",
    "                   [22, 37],\n",
    "                   [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce961b82",
   "metadata": {},
   "source": [
    "input 변수와 target 변수를 별도로 작업할 것이기 때문에 분리했습니다. 또한 일반적으로 훈련 데이터로 작업하는 방식이기 때문에 numpy 배열을 만들었습니다. 일반적으로는 CSV 파일을 numpy 배열로 읽고, 일부 처리한 다음 PyTorch 텐서로 변환합니다.\n",
    "\n",
    "배열을 PyTorch 텐서로 변환해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac63a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Convert inputs and targets to tensors\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "\n",
    "print(inputs, targets, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "790f15e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), torch.Size([5, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d411b6",
   "metadata": {},
   "source": [
    "## Linear regression model from scratch\n",
    "\n",
    "가중치들과 편향(w11, w12,... w23, b1 & b2)은 임의의 값으로 초기화된 행렬로 나타낼 수 있습니다. 'w'의 첫 번째 행과 'b'의 첫 번째 요소는 첫 번째 target 변수, 즉 사과의 수확량을 예측하는 데 사용되며 유사하게 두 번째는 오렌지의 경우에도 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3602af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0366,  0.4488,  0.0023],\n",
      "        [-0.2065, -0.2698, -0.8840]], requires_grad=True)\n",
      "tensor([-0.2932, -0.3910], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "\n",
    "print(w, b, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f7d34",
   "metadata": {},
   "source": [
    "torch.randn은 평균이 0이고 표준편차가 1인 정규 분포에서 무작위로 선택된 요소를 사용하여 주어진 모양의 텐서를 생성합니다.\n",
    "우리의 모델은 단순히 inputs과 가중치 w(전치)의 행렬 곱셈을 수행하고 편향 b(각 예제에 대해 복제됨)를 더하는 함수입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070e9e3",
   "metadata": {},
   "source": [
    "![matrix-mult](https://i.imgur.com/WGXLFvA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e1251",
   "metadata": {},
   "source": [
    "모델은 다음과 같이 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e8fa411",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad906a5",
   "metadata": {},
   "source": [
    "@는 PyTorch에서 행렬 곱셈을 나타내고 .t 메서드는 텐서의 전치(transpose)를 반환합니다.\n",
    "입력 데이터를 모델에 전달하여 얻은 행렬은 대상 변수에 대한 예측 집합입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50958e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  32.5490,  -71.5540],\n",
      "        [  42.6816,  -99.5008],\n",
      "        [  63.1665, -105.7806],\n",
      "        [  22.8252,  -65.7641],\n",
      "        [  45.4807, -102.4198]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a664ba87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459e2fd",
   "metadata": {},
   "source": [
    "무작위 가중치와 편향으로 모델을 초기화했기 때문에 모델의 예측과 실제 목표 사이에 큰 차이가 있음을 알 수 있습니다. 무작위로 초기화된 모델이 그냥 작동할 것이라고 기대할 수는 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe498c",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5fb108",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "모델을 개선하기 전에 모델이 얼마나 잘 수행되고 있는지 평가할 방법이 필요합니다. 다음 방법을 사용하여 모델의 예측을 실제 목표와 비교할 수 있습니다.\n",
    "\n",
    "- 두 행렬(preds 및 targets) 간의 차이를 계산합니다.\n",
    "- 음수 값을 제거하기 위해 차이 행렬의 모든 요소를 제곱합니다.\n",
    "- 결과 행렬의 요소들의 평균을 계산합니다.\n",
    "\n",
    "결과는 평균 제곱 오차(MSE)로 알려진 단일 숫자입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24b3cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff**2) / diff.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a94f4e",
   "metadata": {},
   "source": [
    "'torch.sum'은 텐서에 있는 모든 요소의 합을 반환합니다. 텐서의 .numel 메서드는 텐서의 요소 수를 반환합니다. 우리 모델의 현재 예측에 대한 평균 제곱 오차를 계산해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25530a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18528.6211, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d615a4",
   "metadata": {},
   "source": [
    "결과를 해석하는 방법은 다음과 같습니다. 평균적으로 예측의 각 요소는 손실의 제곱근만큼 실제 목표와 다릅니다. 그리고 우리가 예측하려는 숫자 자체가 50-200 범위에 있다는 점을 고려할 때 이는 매우 나쁩니다. 결과는 모델이 목표 변수를 예측하는 데 얼마나 나쁜지를 나타내기 때문에 손실(loss)이라고 합니다. 이는 모델의 정보 손실을 나타냅니다. 손실이 낮을수록 모델이 더 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75386ee",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52105835",
   "metadata": {},
   "source": [
    "## Compute gradients\n",
    "\n",
    "PyTorch를 사용하면 'requires_grad'가 'True'로 설정되어 있기 때문에 가중치와 편향에 대한 손실의 기울기(gradients) 또는 미분을 자동으로 계산할 수 있습니다. 이것이 얼마나 유용한지 잠시 후에 살펴보겠습니다.\n",
    "\n",
    "기울기는 각 텐서의 '.grad' 속성에 저장됩니다. 가중치 행렬에 대한 손실의 미분은 그 자체가 같은 차원의 행렬임에 유의하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "882fb40d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865a468",
   "metadata": {},
   "source": [
    "기울기는 각 텐서의 '.grad' 속성에 저장됩니다. 가중치 행렬에 대한 손실의 미분은 그 자체가 같은 차원의 행렬임에 유의하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9529ae8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0366,  0.4488,  0.0023],\n",
      "        [-0.2065, -0.2698, -0.8840]], requires_grad=True)\n",
      "tensor([[ -2788.2144,  -3582.2583,  -2138.9863],\n",
      "        [-15022.5654, -16959.9863, -10413.9609]])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for weights\n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a76a849",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9cb3ec",
   "metadata": {},
   "source": [
    "## Adjust weights and biases to reduce the loss\n",
    "\n",
    "손실은 가중치와 편향의 2차 함수이며, 우리의 목표는 손실이 가장 낮은 가중치 집합을 찾는 것입니다. 개별 가중치 또는 편향 요소에 대한 손실 그래프를 플롯하면 아래 그림과 같이 표시됩니다. 미적분학의 중요한 통찰력은 기울기가 가중치와 편향에 대한 손실의 변화율, 즉 손실 함수의 기울기를 나타냅니다.\n",
    "\n",
    "그래디언트 요소가 양수인 경우:\n",
    "* 가중치 요소의 값이 약간 증가하면 손실이 증가합니다.\n",
    "* 가중치 요소의 값이 약간 감소하면 손실이 감소합니다.\n",
    "\n",
    "![postive-gradient](https://i.imgur.com/WLzJ4xP.png)\n",
    "\n",
    "그래디언트 요소가 음수인 경우:\n",
    "* 가중치 요소의 값이 약간 증가하면 손실이 감소합니다.\n",
    "* 가중치 요소의 값이 약간 감소하면 손실이 증가합니다.\n",
    "\n",
    "![negative=gradient](https://i.imgur.com/dvG2fxU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479edd7",
   "metadata": {},
   "source": [
    "가중치 요소를 변경하여 손실의 증가 또는 감소는 그 요소에 대한 손실의 기울기에 비례합니다. 이 관찰은 gradient_를 따라 _descending 모델을 개선하는 데 사용할 gradient descent 최적화 알고리즘의 기초를 형성합니다.\n",
    "\n",
    "손실을 약간 줄이기 위해서 각 가중치 요소에 대한 손실의 미분에 비례하는 소량을 그 요소에서 뺄 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fe7b6fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -2788.2144,  -3582.2583,  -2138.9863],\n",
       "        [-15022.5654, -16959.9863, -10413.9609]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fbec3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e9a5b",
   "metadata": {},
   "source": [
    "가중치를 너무 많이 수정하지 않도록 그라디언트에 매우 작은 수(이 경우 '10^-5')를 곱합니다. 우리는 큰 도약이 아닌 경사의 내리막 방향으로 작은 발걸음을 내딛고자 합니다. 이 수치를 알고리즘의 학습률(learning rate)이라고 합니다.\n",
    "\n",
    "우리는 가중치와 편향을 업데이트하는 동안 그래디언트를 추적, 계산 또는 수정해서는 안 된다고 PyTorch에 나타내기 위해 `torch.no_grad'를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66ecd089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18528.6211, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's verify that the loss is actually lower\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c00c1",
   "metadata": {},
   "source": [
    "계속 진행하기 전에 .zero_() 메서드를 호출하여 그래디언트를 0으로 재설정합니다. PyTorch가 그라디언트를 축적하기 때문에 이 작업을 수행해야 합니다. 그렇지 않으면 다음에 손실에 대해 '.backward'를 호출할 때 새 그라디언트 값이 기존 그라디언트에 추가되어 예기치 않은 결과가 발생할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def6a440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad, b.grad, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acdd04f",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e879da",
   "metadata": {},
   "source": [
    "## Train the model using gradient descent\n",
    "\n",
    "위에서 볼 수 있듯이 경사하강 최적화 알고리즘을 사용하여 손실을 줄이고 모델을 개선합니다. 따라서 다음 단계를 사용하여 모델을 _훈련(train)_할 수 있습니다.\n",
    "\n",
    "1. 예측 생성\n",
    "2. 손실 계산\n",
    "3. 가중치와 편향으로 기울기 계산\n",
    "4. 기울기에 비례하는 소량을 빼서 가중치와 편향을 조정합니다.\n",
    "5. 그라디언트를 0으로 재설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bf85e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 37.9046, -44.7445],\n",
      "        [ 49.7406, -64.2387],\n",
      "        [ 71.6335, -63.9427],\n",
      "        [ 28.0013, -39.2933],\n",
      "        [ 52.3412, -68.4810]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66417306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12637.6855, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15895bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -2233.9573,  -2983.1057,  -1770.0067],\n",
      "        [-12253.0381, -13979.5996,  -8575.6973]])\n",
      "tensor([ -28.2758, -148.1400])\n"
     ]
    }
   ],
   "source": [
    "# Compute gradients\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3264c643",
   "metadata": {},
   "source": [
    "위에서 계산된 그라디언트를 사용하여 가중치와 편향을 업데이트 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db9a6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b273c44c",
   "metadata": {},
   "source": [
    "새로운 가중치와 편향을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf2cf5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0868,  0.5145,  0.0414],\n",
      "        [ 0.0662,  0.0396, -0.6941]], requires_grad=True)\n",
      "tensor([-0.2926, -0.3877], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c653b35",
   "metadata": {},
   "source": [
    "새로운 가중치와 편향을 사용하면 모델의 손실이 낮아집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb482b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8666.2754, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf81fb1",
   "metadata": {},
   "source": [
    "기울기 하강법을 사용하여 가중치와 편향을 약간 조정하는 것만으로 이미 손실을 크게 줄였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f67a1b",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f64fb0e",
   "metadata": {},
   "source": [
    "## Train for multiple epochs\n",
    "\n",
    "손실을 더 줄이기 위해 기울기를 사용하여 가중치와 편향을 조정하는 과정을 여러 번 반복할 수 있습니다. 각 반복을 _epoch_라고 합니다. 100 Epoch 동안 모델을 훈련시켜 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2e76065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 epochs\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65cd33f",
   "metadata": {},
   "source": [
    "다시 한 번 손실이 더 낮아졌는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd32cb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(181.9839, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "loss = mse(model(inputs), targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2172dc69",
   "metadata": {},
   "source": [
    "손실은 이제 초기 값보다 훨씬 낮습니다. 모델의 예측을 보고 목표와 비교해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "882dc126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 60.1999,  74.9325],\n",
       "        [ 80.7183,  95.7132],\n",
       "        [117.1989, 136.7979],\n",
       "        [ 38.6480,  63.4456],\n",
       "        [ 89.0218,  95.0153]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd6338ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db6272b",
   "metadata": {},
   "source": [
    "이제 예측이 목표 변수에 매우 가깝습니다. 몇 에포크를 더 훈련하면 더 나은 결과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd8c9b",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb7ff3",
   "metadata": {},
   "source": [
    "## Linear regression using PyTorch built-ins\n",
    "\n",
    "우리는 몇 가지 기본 텐서 연산을 사용하여 선형 회귀 및 경사 하강 모델을 구현했습니다. 그러나 이것은 딥 러닝의 일반적인 패턴이기 때문에 PyTorch는 몇 줄의 코드로 모델을 쉽게 만들고 훈련할 수 있도록 여러 내장 함수와 클래스를 제공합니다.\n",
    "\n",
    "신경망 구축을 위한 유틸리티 클래스가 포함된 PyTorch에서 torch.nn 패키지를 가져오는 것부터 시작하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "382060ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870770ca",
   "metadata": {},
   "source": [
    "이전과 마찬가지로 input, targe 및 행렬을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ec69304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43],\n",
    "                   [91, 88, 64],\n",
    "                   [87, 134, 58],\n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119],\n",
    "                    [57, 69], \n",
    "                    [80, 102], \n",
    "                    [118, 132], \n",
    "                    [21, 38], \n",
    "                    [104, 118], \n",
    "                    [57, 69], \n",
    "                    [82, 100], \n",
    "                    [118, 134], \n",
    "                    [20, 38], \n",
    "                    [102, 120]], \n",
    "                   dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3117ab9",
   "metadata": {},
   "source": [
    "우리는 15개의 훈련 자료를 사용하여 작은 배치로 대규모 데이터 세트를 작업하는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5a3e59",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242f9c0d",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "\n",
    "PyTorch에서 제공하는 다양한 유형의 데이터세트 작업을 위한 표준 API인 'TensorDataset'을 만들어 'inputs' 및 'targets'의 행에 튜플로 액세스할 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e426dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4a393e",
   "metadata": {},
   "source": [
    "'TensorDataset'을 사용하면 배열 인덱싱 표기법(위 코드의 '[0:3]')을 사용하여 훈련 데이터의 작은 섹션에 액세스할 수 있습니다. 두 개의 요소가 있는 튜플을 반환합니다. 첫 번째 요소에는 선택한 행에 대한 input 변수가 포함되고 두 번째 요소에는 target이 포함됩니다.\n",
    "\n",
    "또한 훈련하는 동안 데이터를 미리 정의된 크기의 배치로 분할할 수 있는 'DataLoader'를 만들 것입니다. 또한 데이터 셔플 및 무작위 샘플링과 같은 다른 유틸리티도 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9af8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c722cb6",
   "metadata": {},
   "source": [
    "우리는 for 루프에서 데이터 로더를 사용할 수 있습니다. 예를 들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfcbddf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 88., 134.,  59.],\n",
      "        [ 74.,  66.,  43.],\n",
      "        [103.,  43.,  36.],\n",
      "        [ 91.,  87.,  65.],\n",
      "        [ 87., 135.,  57.]])\n",
      "tensor([[118., 132.],\n",
      "        [ 57.,  69.],\n",
      "        [ 20.,  38.],\n",
      "        [ 80., 102.],\n",
      "        [118., 134.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdb10e",
   "metadata": {},
   "source": [
    "각 반복에서 데이터 로더는 지정된 배치 크기의 데이터 배치 하나를 반환합니다. shuffle이 True로 설정되면 배치를 생성하기 전에 훈련 데이터를 섞습니다. 셔플링은 최적화 알고리즘에 대한 입력을 무작위화하여 손실을 더 빠르게 줄이는 데 도움이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c797a37",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6275173",
   "metadata": {},
   "source": [
    "## nn.Linear\n",
    "\n",
    "가중치와 편향을 수동으로 초기화하는 대신 자동으로 수행하는 PyTorch의 nn.Linear 클래스를 사용하여 모델을 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "956c4777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2348,  0.1972,  0.5144],\n",
      "        [ 0.5730, -0.0447,  0.0883]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.5373, 0.0472], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = nn.Linear(3,2)\n",
    "\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18cef77",
   "metadata": {},
   "source": [
    "PyTorch 모델에는 모델에 있는 모든 가중치와 편향 행렬을 포함하는 목록을 반환하는 유용한 .parameters 메서드도 있습니다. 선형 회귀 모델의 경우 하나의 가중치 행렬과 하나의 편향 행렬이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "738a64de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2348,  0.1972,  0.5144],\n",
       "         [ 0.5730, -0.0447,  0.0883]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.5373, 0.0472], requires_grad=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a195c2",
   "metadata": {},
   "source": [
    "모델을 사용하여 이전과 같은 방식으로 예측을 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8561510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18.7293, 42.6786],\n",
       "        [29.4468, 53.9084],\n",
       "        [36.3712, 49.0328],\n",
       "        [ 4.1006, 59.8367],\n",
       "        [39.2766, 41.4755],\n",
       "        [18.2973, 43.2962],\n",
       "        [29.7640, 54.0413],\n",
       "        [36.6508, 49.6941],\n",
       "        [ 4.5326, 59.2190],\n",
       "        [40.0259, 40.9909],\n",
       "        [19.0465, 42.8116],\n",
       "        [29.0148, 54.5260],\n",
       "        [36.0540, 48.8999],\n",
       "        [ 3.3514, 60.3213],\n",
       "        [39.7086, 40.8579]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73720ec3",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460ee8e3",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "손실 함수를 수동으로 정의하는 대신 내장 손실 함수 mse_loss를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b8a3f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nn.functional\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa4d8bb",
   "metadata": {},
   "source": [
    "nn.functional 패키지에는 많은 유용한 손실 함수와 기타 여러 유틸리티가 포함되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "959ce8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defin loss function\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f6b22",
   "metadata": {},
   "source": [
    "우리 모델의 현재 예측에 대한 손실을 계산해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "135b9424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3159.9392, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(model(inputs), targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79380be1",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed24d87",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "그라디언트를 사용하여 모델의 가중치 및 편향을 수동으로 조작하는 대신 옵티마이저 'optim.SGD'를 사용할 수 있습니다. SGD는 \"stochastic gradient descent\"의 약자입니다. _stochastic_이라는 용어는 샘플이 단일 그룹이 아닌 무작위 배치로 선택됨을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77fb020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461acc89",
   "metadata": {},
   "source": [
    "model.parameters()는 optim.SGD에 인수로 전달되어 최적화 프로그램이 업데이트 단계 동안 수정해야 하는 행렬을 알 수 있습니다. 또한 매개변수가 수정되는 양을 제어하는 학습률을 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8011fef",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf3511",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "이제 모델을 훈련할 준비가 되었습니다. 우리는 경사하강법을 구현하기 위해 동일한 프로세스를 따를 것입니다:\n",
    "\n",
    "1. 예측 생성\n",
    "2. 손실 계산\n",
    "3. 가중치와 편향으로 기울기 계산\n",
    "4. 기울기에 비례하는 소량을 빼서 가중치를 조정합니다.\n",
    "5. 그라디언트를 0으로 재설정\n",
    "\n",
    "유일한 변경 사항은 모든 반복에서 전체 교육 데이터를 처리하는 대신 데이터 배치를 작업한다는 것입니다. 주어진 epoch 수에 대해 모델을 훈련시키는 유틸리티 함수 'fit'을 정의해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38b63599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl, recode_loss):\n",
    "\n",
    "  # Repeat for given number of epochs\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "    # Train with batches of data\n",
    "    for xb, yb in train_dl:\n",
    "\n",
    "      # 1. Generate predictions\n",
    "      pred = model(xb)\n",
    "\n",
    "      # 2. Calculate loss\n",
    "      loss = loss_fn(pred, yb)\n",
    "      recode_loss.append(loss.item())\n",
    "\n",
    "      # 3. Compute gradients\n",
    "      loss.backward()\n",
    "\n",
    "      # 4. Update parameters using gradients\n",
    "      opt.step()\n",
    "\n",
    "      # 5. Reset the gradients to zero\n",
    "      opt.zero_grad()\n",
    "\n",
    "    # Print the progress\n",
    "    if (epoch+1) % 10 == 0:\n",
    "      print('Epoch [{}/{}], loss: {:.4f}'.format(epoch+2, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e0994",
   "metadata": {},
   "source": [
    "위에서 주의해야 할 사항:\n",
    "\n",
    "* 우리는 이전에 정의한 데이터 로더를 사용하여 모든 반복에 대한 데이터 배치를 가져옵니다.\n",
    "\n",
    "* 매개변수(가중치 및 편향)를 수동으로 업데이트하는 대신 'opt.step'을 사용하여 업데이트를 수행하고 'opt.zero_grad'를 사용하여 그래디언트를 0으로 재설정합니다.\n",
    "\n",
    "* 훈련 진행 상황을 추적하기 위해 매 10번째 epoch에 대한 마지막 데이터 배치의 손실을 인쇄하는 로그 문도 추가했습니다. 'loss.item'은 손실 텐서에 저장된 실제 값을 반환합니다.\n",
    "\n",
    "100 Epoch 동안 모델을 훈련시켜봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "888b53ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], loss: 369.5336\n",
      "Epoch [21/100], loss: 351.5048\n",
      "Epoch [31/100], loss: 105.3316\n",
      "Epoch [41/100], loss: 119.3316\n",
      "Epoch [51/100], loss: 84.1856\n",
      "Epoch [61/100], loss: 87.7183\n",
      "Epoch [71/100], loss: 55.4246\n",
      "Epoch [81/100], loss: 53.5232\n",
      "Epoch [91/100], loss: 25.1330\n",
      "Epoch [101/100], loss: 28.1458\n"
     ]
    }
   ],
   "source": [
    "# loss값 저장을 위한 list\n",
    "loss = []\n",
    "\n",
    "fit(100, model, loss_fn, opt, train_dl, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0fd7b",
   "metadata": {},
   "source": [
    "모델을 사용하여 예측을 생성하고 목표에 가까운지 확인하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75dd4c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.7260,  72.2928],\n",
       "        [ 82.7133,  98.7020],\n",
       "        [115.8121, 134.6786],\n",
       "        [ 24.4899,  47.8252],\n",
       "        [100.9784, 109.3830],\n",
       "        [ 56.5921,  71.4009],\n",
       "        [ 82.6421,  98.3293],\n",
       "        [116.1701, 135.0903],\n",
       "        [ 25.6237,  48.7171],\n",
       "        [102.0411, 109.9022],\n",
       "        [ 57.6547,  71.9202],\n",
       "        [ 81.5795,  97.8101],\n",
       "        [115.8833, 135.0512],\n",
       "        [ 23.4272,  47.3059],\n",
       "        [102.1123, 110.2749]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac5413b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 57.,  69.],\n",
       "        [ 80., 102.],\n",
       "        [118., 132.],\n",
       "        [ 21.,  38.],\n",
       "        [104., 118.],\n",
       "        [ 57.,  69.],\n",
       "        [ 82., 100.],\n",
       "        [118., 134.],\n",
       "        [ 20.,  38.],\n",
       "        [102., 120.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd077f2",
   "metadata": {},
   "source": [
    "실제로, 예측은 우리의 목표에 매우 가깝습니다. 우리는 한 지역의 평균 기온, 강우량, 습도를 보고 사과와 오렌지의 수확량을 예측할 수 있는 합리적으로 좋은 모델을 훈련했습니다. 단일 입력 행을 포함하는 새로운 지역의 배치를 전달하여 작물 수확량을 예측하는 데 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a53e452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55.2596, 68.6450]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([[75., 63, 44]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c8fc86",
   "metadata": {},
   "source": [
    "사과의 예상 수확량은 헥타르당 55.2톤이고 오렌지는 헥타르당 68.6톤입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e86230dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlVElEQVR4nO3deZgU1bk/8O/LsMZh1WGZBQd/4oJoVLgENBrFBSQqxBtySTTiFu41ajTXJILGJclFxahRcwOGxAiiRnFJwIUYQjTqIxccDLLINizDIjAIsivIzPv7462Tqurqnp6BGXqm6vt5nn6q+nRV9Sl6+J5Tp6qrRVVBRETJ0CzXFSAiosOHoU9ElCAMfSKiBGHoExElCEOfiChBmue6AtkcddRRWlpamutqEBE1KfPmzftEVQtSyxt96JeWlqKsrCzX1SAialJEpCJdOYd3iIgShKFPRJQgDH0iogRh6BMRJQhDn4goQRj6REQJwtAnIkqQ2Ib+r38NPP98rmtBRNS4xDb0H38cePHFXNeCiKhxiW3oN2sGVFXluhZERI1LbEM/Lw+ors51LYiIGpfYhn6zZgx9IqJUsQ59Du8QEYXFNvQ5vENEFBXb0GdPn4goKrahz54+EVFUbEOfPX0ioqjYhj57+kREUbENffb0iYiiYhv67OkTEUXFNvT55SwioqhYhz6Hd4iIwmIb+hzeISKKim3os6dPRBQV29BnT5+IKKrWoS8ieSLyTxF51XveSURmisgKb9oxsOwYESkXkWUiMihQ3kdEFnqvPSYiUr+742NPn4goqi49/ZsBLAk8Hw1glqr2BDDLew4R6QVgBICTAAwGMF5E8rx1JgAYBaCn9xh8SLWvAXv6RERRtQp9ESkG8HUAvw8UDwUw2ZufDGBYoPw5Vd2nqqsBlAPoJyLdALRT1dmqqgCeCqxT73jJJhFRVG17+o8A+AmAYIx2UdWNAOBNO3vlRQDWBZZb75UVefOp5REiMkpEykSkbMuWLbWsYhiHd4iIorKGvohcDKBSVefVcpvpxum1hvJooepEVe2rqn0LCgpq+bZhHN4hIopqXotlzgRwqYgMAdAaQDsReRrAZhHppqobvaGbSm/59QBKAusXA/jYKy9OU94g2NMnIorK2tNX1TGqWqyqpbATtH9X1SsATAcw0ltsJIBp3vx0ACNEpJWI9ICdsJ3rDQHtEpH+3lU7VwbWqXfs6RMRRdWmp5/J/QCmisi1ANYCGA4AqrpYRKYC+AjAAQA3qKrrc18PYBKANgBmeI8GwZ4+EVFUnUJfVd8C8JY3vxXAeRmWGwtgbJryMgC961rJg8GePhFRVGy/kcuePhFRVGxDnz19IqKo2IY+v5xFRBQV69Dn8A4RUVhsQ5/DO0REUbENffb0iYiiYhv67OkTEUXFNvTZ0yciiopt6LOnT0QUFdvQb9YMULUHERGZWIc+wN4+EVFQbEM/z/uBRoY+EZEvtqHvevo8mUtE5Itt6LOnT0QUFdvQZ0+fiCgqtqHPnj4RUVRsQ589fSKiqNiHPnv6RES+2IY+h3eIiKJiG/oc3iEiiopt6LOnT0QUFdvQZ0+fiCgqtqHPnj4RUVRsQ589fSKiqNiGPnv6RERRsQ19XqdPRBQV+9Dn8A4RkS+2oc/hHSKiqNiGPnv6RERRsQ199vSJiKJiG/rs6RMRRcU29NnTJyKKim3os6dPRBQV+9BnT5+IyBfb0OfwDhFRVNbQF5HWIjJXRD4UkcUi8jOvvJOIzBSRFd60Y2CdMSJSLiLLRGRQoLyPiCz0XntMRKRhdovDO0RE6dSmp78PwEBV/TKAUwEMFpH+AEYDmKWqPQHM8p5DRHoBGAHgJACDAYwXEa/fjQkARgHo6T0G19+uhLGnT0QUlTX01ez2nrbwHgpgKIDJXvlkAMO8+aEAnlPVfaq6GkA5gH4i0g1AO1WdraoK4KnAOvWOPX0ioqhajemLSJ6IzAdQCWCmqs4B0EVVNwKAN+3sLV4EYF1g9fVeWZE3n1qe7v1GiUiZiJRt2bKlDrvjY0+fiCiqVqGvqlWqeiqAYlivvXcNi6cbp9caytO930RV7auqfQsKCmpTxQj29ImIoup09Y6qbgfwFmwsfrM3ZANvWuktth5ASWC1YgAfe+XFacobBHv6RERRtbl6p0BEOnjzbQCcD2ApgOkARnqLjQQwzZufDmCEiLQSkR6wE7ZzvSGgXSLS37tq58rAOvWO1+kTEUU1r8Uy3QBM9q7AaQZgqqq+KiKzAUwVkWsBrAUwHABUdbGITAXwEYADAG5QVTfIcj2ASQDaAJjhPRoEh3eIiKKyhr6qLgBwWpryrQDOy7DOWABj05SXAajpfEC94fAOEVFUbL+Ry54+EVFUbEOfPX0ioqjYhj57+kREUbENffb0iYiiYhv6vGSTiCgq9qHP4R0iIl9sQ5/DO0REUbENffb0iYiiYhv67OkTEUXFNvTZ0yciiopt6LOnT0QUFdvQZ0+fiCgqtqHPnj4RUVRsQ59fziIiiop96HN4h4jIF9vQ5/AOEVFUbEOfPX0ioqjYhj57+kREUbENfRGbsqdPROSLbegD1ttnT5+IyBfr0G/WjKFPRBQU+9Dn8A4RkS/Woc/hHSKisFiHPnv6RERhsQ599vSJiMJiHfrs6RMRhcU69NnTJyIKi3Xos6dPRBQW+9BnT5+IyBfr0OfwDhFRWKxDn8M7RERhsQ599vSJiMJiHfrs6RMRhcU69NnTJyIKi3Xos6dPRBQW69BnT5+IKCxr6ItIiYi8KSJLRGSxiNzslXcSkZkissKbdgysM0ZEykVkmYgMCpT3EZGF3muPibjft2oYvE6fiCisNj39AwBuVdUTAfQHcIOI9AIwGsAsVe0JYJb3HN5rIwCcBGAwgPEi4v1iLSYAGAWgp/cYXI/7EpGXBxw40JDvQETUtGQNfVXdqKofePO7ACwBUARgKIDJ3mKTAQzz5ocCeE5V96nqagDlAPqJSDcA7VR1tqoqgKcC6zSIli2BL75oyHcgImpa6jSmLyKlAE4DMAdAF1XdCFjDAKCzt1gRgHWB1dZ7ZUXefGp5uvcZJSJlIlK2ZcuWulQxpEULYP/+g16diCh2ah36IpIP4CUAt6jqzpoWTVOmNZRHC1UnqmpfVe1bUFBQ2ypGtGzJ0CciCqpV6ItIC1jgP6OqL3vFm70hG3jTSq98PYCSwOrFAD72yovTlDcYDu8QEYXV5uodAfAEgCWq+nDgpekARnrzIwFMC5SPEJFWItIDdsJ2rjcEtEtE+nvbvDKwToNgT5+IKKx5LZY5E8B3ASwUkfle2e0A7gcwVUSuBbAWwHAAUNXFIjIVwEewK39uUFX3FanrAUwC0AbADO/RYBj6RERhWUNfVd9F+vF4ADgvwzpjAYxNU14GoHddKngoeCKXiCgs1t/IZU+fiCgs9qHPE7lERL7Yhz57+kREPoY+EVGCxDr0eSKXiCgs1qHPnj4RUVjsQ7+qirdXJiJyYh/6AK/gISJyEhH6HOIhIjIMfSKiBIl16LdoYVOGPhGRiXXos6dPRBSWiNDniVwiIpOI0GdPn4jIMPSJiBIk1qHvTuQ+8ggwaVIua0JE1DjEOvRdT3/yZODpp3NbFyKixiARoQ9wiIeICEhQ6O/bl7t6EBE1FokJ/f37gYkTgccfz119iIhyLdah707kAhb6U6YATz2Vu/oQEeVa81xXoCGl9vT37eNtloko2RIT+vv2MfSJiBIT+uzpExEx9ImIEiUxoe+Gd1RzVx8iolyLdeinXr3D0CeipIt16Ad7+gcOAJ9/nru6EBE1BrEO/eYpe7d3L5CXl5u6EBE1BrH+cpZIuLcPAFVV9iAiSqJYhz4QDX2AN18jouSKfegHT+Y6vPkaESVV7EM/XU+foU9ESZXI0OfwDhElVSJDnz19IkqqrKEvIn8QkUoRWRQo6yQiM0VkhTftGHhtjIiUi8gyERkUKO8jIgu91x4TEan/3Yli6BMR+WrT058EYHBK2WgAs1S1J4BZ3nOISC8AIwCc5K0zXkTclfETAIwC0NN7pG6zQRzqidzycuDJJ+uvPkREuZQ19FX1bQDbUoqHApjszU8GMCxQ/pyq7lPV1QDKAfQTkW4A2qnqbFVVAE8F1mlQF10EDBkSLqvLmP6kScC11/L2DUQUDwc7pt9FVTcCgDft7JUXAVgXWG69V1bkzaeWN7j77wfuuCNcVpee/mefWeDz5C8RxUF9n8hNN06vNZSn34jIKBEpE5GyLVu2HHKlUsf16xL6LuwZ+kQUBwcb+pu9IRt400qvfD2AksByxQA+9sqL05SnpaoTVbWvqvYtKCg4yCr6WrUKP9+3Dxg/HrjzzuzrugaCJ3+JKA4ONvSnAxjpzY8EMC1QPkJEWolID9gJ27neENAuEenvXbVzZWCdBpfa09+/H3j2WeC3v82+rgt79vSJKA6y3mVTRP4I4BwAR4nIegB3A7gfwFQRuRbAWgDDAUBVF4vIVAAfATgA4AZVdbc3ux52JVAbADO8x2GRbnhn3TpgyxZg2zagU6fM67KnT0RxkjX0VfXbGV46L8PyYwGMTVNeBqB3nWpXT1JDf+9eYMMGm1+2DBgwIPO67OkTUZzE/hu5QHRMf80a//bKy5bVvC57+kQUJ4kI/dSefnm5P790afp1JkwA+vVjT5+I4iXRod+qlfX0N2wAFi0KL/P97wPvv5++p790KXDjjfwxFiJqehIZ+itW2HTAAGsA7roL+Pd/t/KZM8PL7t1r02BP//XXgd/8Bvg440WnRESNUyJCv1kz+73c5s3tJxR37gTatQO6dwd27QK2brUrecaNA77znfC627fbNNjT3707/BoAVFcDH3zQkHtBRHToEhH6gPX2W7XyT+p27w4ccQSwZ4+F+M6dFv6ffAIcOOCv54I92NPftSv8GgDMmAH06RM+X0BE1NgkLvTdUE9JiR/6e/bY+LwbrvnkE3+9HTtsmq6n/+GHwA9/aOtu3mxlmzY17H4QER2KxIS+6+UHe/r5+XZDtZ07rWztWpsGg7u62qbBnr4L/cmTgUceAVavtoYD8BuJbFau9LdNRHS4JCb0U4d3XE8fsPF8wA97d6I3KNjTd8M77hr/3bv9hqA2ob9xI3D88cD06XXbByKiQ5X1G7lx0bKlncjN837SpXt3P6iDwzkA8NFH0fXT9fRd+Nc19DdsCA8nEREdLonp6btefnBMPz/f5lN/ICVd6Kcb0w8+r8vwzrZt6bdDRNTQEhP6ma7eSWfJkmhZup5+8HldevqffmrTPXuAzz8HTj4ZmDUr+3pERIcqkaEvAhQVZQ79bMM7bljHCYZ+8DLOTFzo797tfxv4n//Mvh4R0aFKTOifeKI9WrUCunSxqRveSZXu9gr1ObwTDH031OO++VtdDfTtC0ydmn07RER1lZgTuZMm2fSyy4DjjrP5dD39vLz0od9Qwzupob97NzBvHvDuu3Y5af/+dqUPEVF9SExP3xk/3n41C8gc+gDwta+Fy4N320y942ZdQz94ItfNpx4pVFQAV19t9/gBgNtuA159Nfu2iYhqkrjQ79rVxvOB9KF/663AoEHACy+Ey13Qu3B3jYMrq6/hHbf+3Ll2VdH69fb8f/8XePnl9Nu78ELgm9/M/r5ERIkZ3kkn3Zj+TTcB3bpZ4Ir4l3O6nr4L/aIi/xu8hzK8s3WrzaeGvvui2Pr19t579/oniYcMAU4/Hfif/7Hn7s6gL75ojdE3vuG/15tv2ra+nen3z4goURLX0w8K9vRbt7Zp+/Y2FQHatPFfdz19d+VOSYlNW7aMhn7qdf+p0vX09+yxG72lNhrr1vnLb98OfPGFhfzkydH3GT0auOeecNn99wM/+UnN9SGi5Eh06Ofl+dftFxYCLVqEgz44v327/XiKC/eRI4Ff/ALo3Tsc+jt3Am3bAr/8JbB8OTB7tn9ieMEC4JhjgPnz7Xkw9D/91I4wJkwI13HzZqCy0uZ37LB79hw4YEcAqT/8snKl3UIieE+figr75i9/+YuIgISHPuAP8XTrZr18Ef+1YOi/8opd8rl8uT0//njgpz+1gN+2zXrgnTrZa3v2WO/6+OOBM86w4ZhbbrHp6tX+NoNX76xbZ7eDePvtcP1UgcWLbd41PM6MGdHe/mef2bbcumvXWiPgzg0ErVwJvPRStn8hIoqTxIe+G+K55hrghhvCrwVD35kyxaauscjP92+rXFBg07POAv7+d+DJJ4H77gP+8Q/giSfCDQoQ7ulv3GhTd8fPoIULbbp9u/9t4cJCO9nrzgUEuRvBbdlijQBgPf5Ut90GfOtb/knoVIsX27kA/ig8UXww9L3Qv+KK6Hi4C/0vfckvcydN27a1aX6+f9LVlV1+OXDuucBVV9k4+549di5g3Tq7/77z2Wf+HT7TDb8ce6xNFyyw6Y4dFvqFhTZMtHVr+NvBbqjKHQ0Egz419PfutSOF6mr7XYB0/vIX4Lnn/EYn1SefWKPhGi4iavwSH/r5+Xb3zdTf0QX80G/XLv16bup62zfdZJd6jhoVXjZ4eefgwTbt2tWmbigmyJ1UHjDApi70q6qAsjIbZjrySAvb4JHBeefZEJXr6a9Z478WnAeAN97w653pZx7duYR0t6UA7AjmhRescbjiCv+Ih4gar8SH/hFHZL4Hjwt914M//3zguuvsZxGPPNLKgpd9duxo18unDuMEXXihheXtt9vzdEMnhYXA9dfbkFP79uGGYelSoGdPO38Q7On/4Q/A00/beQQX+q53365dtKf/2mtAhw42JDVvXvq6uqOQTKHvGpLp04FnnrEfjK+N5cuBo4+2+hLR4cXQr0Xou55+URHwu99Zb9sdGQRDP9O9fFKdfbY1EI4blnHat7dvDp9zjn/LCEcV6NEj2tPv0cO2efTR/knbigqr+8knR3v6b79t9ejbN3Pou56+O5GcyjUkbngo9WqidA4csIZv7VrgT38Kv/bBB3a30WBDuGBB+OQ3ER2axId+YaFduZNOak/fnagNcq8BmRuPdILLpt5bx31XAIiGPmDBfuSRdk7ABbOrR2Gh/+MsFRVAaamF/jvv2DmLTZvssWKFnXD+8petJx/8MXh3yWe24R0X+u6KpkyNQ9BHH/nruZPXgDVmF1xgR1OjR/vll19uw2ZEVD8SH/oPPGCXY6bjQr+5973lo46KLhMM73Rj/5kEjwrOPTf8WjD0091srbTUvzzU9eCDob9rlz0qKqyBGDcOGDYM+NnPgFNPBaZNs2XPPtu2VVVlDcHixbZc1652y2c3vLNqFVBcbP9OxcV+z9uFt2skatPTLyuz6cCBNlTlLjndts0/Ibxqlb/8unW12y4R1U7iQ79Dh+w9/c8/t2m60Hdj+5deWre7YQZD/8QTw6/VtqcPhMftAQt9wHrRLvTbtbNbNLz3np0HuOkmayROO81CHLAGoXdvO8G7Y4ddzllZaQ1Sx47WCFx3nU3dF8hSzxNs2JD99wTKyqw+F19sX0hzP1UZDHp3Qvizz6wuFRX1+ytjK1bY/mb75jRRHCU+9GuSGvrphncuuwx46y3gz3+u+QRuquARQuqwUE2h37q1/R5ATT19wC7t3LHDQt8ZMAC49147ET19un0D2d1O4oUXbP8qKuyy0meesat7Bg2yhqJ7d3+454kn7DsNwYBv5v0lLV5sRxl33mnrPvZY+KqesjJ7f9fQuctLV6606amn+u8TXG/JErsZ3oMP2vOJE4GHHgr/27gGwnnpJbtsFrCT5//5nxb0TzxhQ13prpwiijuGfg0KCqyX666QSdfTb9XKbsNcl8B36wE2xOK+B+Au4wyGfs+e4fWOPtrey/X016yxwHXbcKE/e7a/fNCPf2yvnXOOPXehv2MH0KsX0Llz+IZtnTvb+11yiT2/+mprDMaPt+eu8enXz6Zz5thvANx7rw0D3Xyz7ddxx9lvBHz4oZ08dkdF7kojF/r9+1vY33038Ktf+fW49Vbg4YftfVUttH/xC/9cRHW1NUylpX4P/vHH7R5FW7cCjzxiDUVlpX/uYd48a+xq0+PfutW+Ub1une1Hut9cIGoSVLVRP/r06aO5snOn6rJlqt26qQKqy5fX37arq1UffVT1k09U//IX2/5Xv6o6ZIjqzJnhZYcNU332WdU2bVQvvNDK1q2zddq0UW3f3l92xw4rP+ssm86Zk70eRxxhy44aZWX79tlzQPWVV6zsgw9Uv/IVq291ter48fb6iBE2vflm207Pnvb8j3+09crKVB98ULVVK9Wvfc1ee/551QMHVFu3Vr31VlvummtUu3ZVvf9+W6ZVK9Vmzfx6AKrt2tn0jTf8sjlzVKdPVx082C9budL2oU0bez5jhmrbtjb/j3+o9uhh8+3b2/TFF7N/XtOn27LXXWfTKVOyr0OUSwDKNE2m5jzUsz1yGfqOC8Vt2xpm+2+/bdu/5JKal+vVS/VHP7L5vXv9kCsu9pdxId68ub22aVP29z/hBFv2oYf8smCoZvLFF6q/+Y0tN26car9+Ni9ijU/QGWf421y1yspOPln14outYT3hBNUzz1R98slw0AOqRUWqxx6r+uc/2/Pgtn76U9XOnS3A3fsPH67au7e/zKWX+vO/+lV0+8cdZw36ddep7toV3c+9e1UfecRvZAHVkSP911J9+qk1ZgsWZP+3f/xx1Vdfzb4cUV0x9A/BlCmqJSWqVVUNs/2yMvskrrii5uW2bVP97DP/eevWtl6vXuHljjvOylu3tkYgmwsusOWD4VNaamXl5TWv+8ILttxTT6lefbXNn3BCdLlbbrHXOnXy6zR8uOrRR6t+6Uv+/r/+ejiQRVQrKuwIY+dOv/wrX7FGo2VLe/7OO/b5dOgQXt89b9EifLSR+nBHRt/4hs1fc401gq6BOfvs8PLdu6vOn291HzfO9ufdd60Bdp/L1VerVlaGP7OgrVut/r16qW7YYPv4zjuq771nr69apXrRRarf+1769Tdtsjr8/e+qP/yhLT9pUs2fl2rm+lC8MPQbsSVL7JO44Ya6rVdU5Adg0LnnWvmxx9ZuO9dcY8uvWOGXLVum+oMfZG/o5s+3df/v/ywkAdXvfje63LPP2mtueErVeukuRI891o4qXAPoHgUF4e248vffV/3b31QHDFC98kr/9a9/3RqKsWNV77vPQhiwfTnlFH9916jddpt/VBQ8sujYUUM9++DDDTudfLJN8/JUH3vMlu3Z0z7HI46wxq9DByv//e9Vp01T/fa3LaA3bPCHyFxjWFJijUibNqoffqjap4//+hdfqO7fb8NMM2eqLl1q9WzdWvW002wZN12/3v4tqqpsGDDoqaes8fvoo3D5pk2q3/++6po1NX/eTllZ+Giups7FqlWqmzfXbrtUfxj6jVhFhX0St99et/UGDrT1jj8+XD53ruqPf6z68su1285jj6l26WLBcjBWr7apOzfx6KPRZcrL7bUxY/yyp5/2Q82FkztX4R4nnxzezptvqv71r5nrUlYWHm9/8EEL5W3bbCgJsHAdNcrmX39d9ZxzbP5731O96SYLqKoqC+bqajsaAfzG4TvfsYbFDWuddJLNd+2qunGjve/tt0cbC0D1qKNsO6ecYuuVlPivtWhhjUS3bjZkBdh5Hnck4446Wre2xs6dp0h93HKL6n/9l+r11+u/jl5+/3sLfHfk84Mf2N/JGWfY+ZrLLrPyfv1sHy64wOr2zjt2tFJVZf8W1dW2bUC1sNCObiorrREdOND+llevtkb3vffs3E1xsWr//laHP/2pTn9a/1JRoTpvns2vXGnDisGGZtUq1f/+7/BRTHW1NY5J1WhCH8BgAMsAlAMYnW35JIT+1q32STzwQN3W27jR/tPeddehvX9VleqePYe2DVXbxqhRqh9/HH2tutr+02/Y4Je9/77+a6jEcSeRjznGerwXXHDo9XKNmRti+tvfVCdMsJDdvFn1l7+08rKy9OsPH+6HZ8uWFnSrV/tDX5s22Qntd9/113HnH9q1syB65hnr6e/fbyfH3RHCK69Yo+PWnzfPgrZ5c1t33jw/zJs3V737bv/5z3/un8dwJ9Dz8sINQP/+qkce6T8vKLCGpH17+zd2jQhgFxG4cxyAHe0cf7y9b2GhLecakquusvfs0MHOxbRsqZqfr3r++fYebjszZoTr06GD6sMPW6PwrW9ZAzdokOp559l27rrLGtXnn1d96y0bcrztNmtkRazhGjbMtjV1qv1d7djh12vsWNXXXrOjqXvvtbK777ZG7fTT7Qi2stI+hylTVCdOtGHDV16x9543z1576CHVxYut0Zo4UXXRovDf8pQp/t/LqlV2HqeqytZxR0AvvmiP9eujR1Y7dvgdhKD6HEJuFKEPIA/ASgDHAGgJ4EMAvWpaJwmhr2p/WOnCMs7cGP2IEeHyDh1sLPuqqyyQ68v27aqzZ9v8/v3+1Vh799qwSSYPPGD1nDDBGqXa2LDB1vmP/0j/+m9/a0dGqhYiqf/ZX3vNgqiqyg9M17j3728N1saNdjXSPffYtq66yhomQPXyy22Ybfdu20Z5uQXP/v3Ws+/Sxbbx61/beY5HH7WAu+giW/+ii/z9Li21oHVDYvn5dsJ79Woblmvb1k5IB49uXANbUmINTGGhvWewAcjLs+GuwkI7snFHLp06hZcDbAjyvPP88M/Ls8blrLNsuKptW//oK93DDbO5ixaCdXHDpG7o7thj/UZvwACbb9vWzjmNHOn/G7Vtaw2Va+DcxQPFxdYgu4a6a1ebP+UUu8rs0kutQc/PV73jDjtCeeABO6rt0sWOOLt1s+G91Asi6qKxhP4AAG8Eno8BMKamdZIS+kn185/7Qezceaf14hqLOXPsf4o7wVpb991n5zwOlTu/8Omn9nzhQjtqSGfaNDvpnO6qoqDqamsAUi1aZCH8zjsWOCNHWiPhtg2oXntteDtORYWFZv/+1tD07WvLjx5tvd1t21SHDrXzLm+/bcNLqrasa5jckNBbb6m+9JLqc8/ZlVPV1XYkOXCgnff461/tKKdjRz+0H3/cGpupU+18Sfv21tO+8kob5hkzxpbr1csCdtIk67E3a2ZHqJWV1nCddJL9XZ5xhi07bpwdcfboYUN9JSV2JNGzpz1Gj7Y6dexoRzGu0Ro40MI7P9/ee8gQC/JTTrHG7sQT9V/Dem5ozV1OfMklNhxZmwsxMskU+mKvHR4i8k0Ag1X1Ou/5dwF8RVVvTFluFIBRANC9e/c+Fel+9onoMFq71r78lQvLl9uX5/7t33Lz/o4q8Oij9i30TP8WU6fal/x69/b72c2ahbdR1y8yBh04YF+U69LFL1u2zG4zcttt/n2y3LLB59u3232obrzR7pjrbNtmX8Ksa72qq/19W7HCvllfWGj127LFvoC4Zo39QFK6W7Ts3Gn3vOrSxW5JUlpq6y5dCpx5Zt3qko6IzFPVvpHywxz6wwEMSgn9fqqa8T6Kffv21TJ3ly4iIqqVTKF/uG/DsB5ASeB5MYCPD3MdiIgS63CH/vsAeopIDxFpCWAEgOmHuQ5ERInVPPsi9UdVD4jIjQDegF3J8wdVrcVPbxARUX04rKEPAKr6OoBa/poqERHVJ95amYgoQRj6REQJwtAnIkoQhj4RUYIc1i9nHQwR2QLgYL+SexSAT+qxOrnEfWmcuC+NT1z2Azi0fTlaVSO/7N3oQ/9QiEhZum+kNUXcl8aJ+9L4xGU/gIbZFw7vEBElCEOfiChB4h76E3NdgXrEfWmcuC+NT1z2A2iAfYn1mD4REYXFvadPREQBDH0iogSJZeiLyGARWSYi5SIyOtf1qSsRWSMiC0VkvoiUeWWdRGSmiKzwph1zXc90ROQPIlIpIosCZRnrLiJjvM9pmYgMyk2t08uwL/eIyAbvs5kvIkMCrzXmfSkRkTdFZImILBaRm73yJvfZ1LAvTeqzEZHWIjJXRD709uNnXnnDfibpfkOxKT9wED++3tgeANYAOCql7AEAo7350QDG5bqeGep+NoDTASzKVncAvbzPpxWAHt7nlpfrfciyL/cA+FGaZRv7vnQDcLo33xbAcq/OTe6zqWFfmtRnA0AA5HvzLQDMAdC/oT+TOPb0+wEoV9VVqrofwHMAhua4TvVhKIDJ3vxkAMNyV5XMVPVtANtSijPVfSiA51R1n6quBlAO+/wahQz7kklj35eNqvqBN78LwBIARWiCn00N+5JJo9wXNbu9py28h6KBP5M4hn4RgHWB5+tR8x9EY6QA/ioi87wfiQeALqq6EbA/egCdc1a7ustU96b6Wd0oIgu84R936N1k9kVESgGcButZNunPJmVfgCb22YhInojMB1AJYKaqNvhnEsfQT/eb9k3tutQzVfV0ABcBuEFEzs51hRpIU/ysJgD4fwBOBbARwENeeZPYFxHJB/ASgFtUdWdNi6Ypa1T7k2Zfmtxno6pVqnoq7PfC+4lI7xoWr5f9iGPoN/kfX1fVj71pJYA/wQ7hNotINwDwppW5q2GdZap7k/usVHWz9x+1GsDv4B9eN/p9EZEWsJB8RlVf9oqb5GeTbl+a8mejqtsBvAVgMBr4M4lj6DfpH18XkSNEpK2bB3AhgEWwfRjpLTYSwLTc1PCgZKr7dAAjRKSViPQA0BPA3BzUr9bcf0bPN2CfDdDI90VEBMATAJao6sOBl5rcZ5NpX5raZyMiBSLSwZtvA+B8AEvR0J9Jrs9gN9BZ8SGwM/orAdyR6/rUse7HwM7Qfwhgsas/gCMBzAKwwpt2ynVdM9T/j7BD6y9gPZNra6o7gDu8z2kZgItyXf9a7MsUAAsBLPD+E3ZrIvvyVdhQwAIA873HkKb42dSwL03qswFwCoB/evVdBOAur7xBPxPehoGIKEHiOLxDREQZMPSJiBKEoU9ElCAMfSKiBGHoExElCEOfiChBGPpERAny/wFNakb2+zwsDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8408a41",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa44e25",
   "metadata": {},
   "source": [
    "## Machine Learning vs. Classical Programming\n",
    "\n",
    "이 튜토리얼에서 우리가 취한 접근 방식은 여러분이 알고 있는 프로그래밍과 매우 다릅니다. 일반적으로 일부 입력을 받고 일부 작업을 수행하고 결과를 반환하는 프로그램을 작성합니다.\n",
    "\n",
    "그러나 이 노트북에서는 일부 알려지지 않은 매개변수(가중치 및 편향)를 사용하여 표현되는 입력과 출력 간의 특정 관계를 가정하는 \"모델\"을 정의했습니다. 그런 다음 모델에 일부 알려진 입력 및 출력을 보여주고 모델을 _훈련_ 하여 알려지지 않은 매개변수에 대한 좋은 값을 도출합니다. 훈련을 마치면 모델을 사용하여 새 입력에 대한 출력을 계산할 수 있습니다.\n",
    "\n",
    "이러한 프로그래밍 패러다임을 _머신 러닝_ 이라고 하며, 여기서 데이터를 사용하여 입력과 출력 간의 관계를 파악합니다. _딥 러닝_ 은 행렬 연산, 비선형 활성화 함수 및 경사하강법을 사용하여 모델을 구축하고 훈련하는 기계 학습의 한 분야입니다. Tesla Motors의 AI 이사인 Andrej Karpathy는 [Software 2.0](https://medium.com/@karpathy/software-2-0-a64152b37c35)이라는 제목으로 이 주제에 대한 훌륭한 블로그 게시물을 작성했습니다.\n",
    "\n",
    "Francois Chollet의 책 [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)의 이 그림은 고전적 프로그래밍과 기계 학습의 차이점을 포착합니다.\n",
    "\n",
    "![](https://i.imgur.com/oJEQe7k.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
