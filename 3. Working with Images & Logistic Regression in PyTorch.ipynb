{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5dfd3bf",
   "metadata": {},
   "source": [
    "# Working with Images & Logistic Regression in PyTorch\n",
    "\n",
    "* PyTorch에서 이미지 작업(MNIST 데이터 세트 사용)\n",
    "* 데이터 세트를 훈련, 검증 및 테스트 세트로 분할\n",
    "* nn.Module 클래스를 확장하여 사용자 정의 로직으로 PyTorch 모델 생성\n",
    "* Softmax를 사용하여 모델 출력을 확률로 해석하고 예측된 레이블 선택\n",
    "* 분류 문제에 대한 유용한 평가 지표(정확도) 및 손실 함수(교차 엔트로피) 선택\n",
    "* 검증 세트를 사용하여 모델을 평가하는 훈련 루프 설정\n",
    "* 무작위로 선택한 예제에서 수동으로 모델 테스트\n",
    "* 처음부터 다시 학습하지 않도록 모델 체크포인트 저장 및 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38d3bdc",
   "metadata": {},
   "source": [
    "## Working with Images\n",
    "\n",
    "이 파트에서는 PyTorch 및 선형 회귀(linear regression)에 대한 기존 지식을 사용하여 매우 다른 종류의 문제인 이미지 분류를 해결합니다. 우리는 훈련 데이터 세트로 유명한 MNIST 손으로 쓴 숫자 데이터베이스를 사용할 것입니다. 손으로 쓴 숫자(0~9)의 28픽셀 x 28픽셀 그레이스케일 이미지와 각 이미지가 나타내는 숫자를 나타내는 레이블로 구성됩니다. 다음은 데이터세트의 샘플 이미지입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec41efb",
   "metadata": {},
   "source": [
    "![mnist-sample](https://i.imgur.com/CAYnuo1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dbf1cd",
   "metadata": {},
   "source": [
    "먼저 torch 와 torchvision을 (설치하고) 가져옵니다. torchvision 에는 이미지 데이터 작업을 위한 몇 가지 유틸리티가 포함되어 있습니다. 또한 MNIST와 같은 인기 있는 데이터 세트를 자동으로 다운로드하고 가져올 수 있는 도우미 클래스를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f159f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "dataset = MNIST(root='data/', download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364c9aed",
   "metadata": {},
   "source": [
    "이 명령문이 처음 실행되면 노트북 옆의 data/ 디렉토리에 데이터를 다운로드하고 PyTorch Dataset을 생성합니다. 후속 실행에서는 데이터가 이미 다운로드 되었으므로 download=False로 바꿔 다운로드를 건너뜁니다. 데이터 세트의 크기를 확인합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a88799b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26edb93f",
   "metadata": {},
   "source": [
    "데이터 세트에는 모델을 훈련하는 데 사용할 60,000개의 이미지가 있습니다. 또한 모델을 평가하고 지표를 보고하는 데 사용되는 10,000개 이미지의 추가 테스트 세트가 있습니다. train=False를 생성자에 전달하여 MNIST 클래스를 사용하여 테스트 데이터 세트를 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4a0d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = MNIST(root='data/', train=False)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f8eb4",
   "metadata": {},
   "source": [
    "훈련 dataset의 샘플 요소를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c32b073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x171613FE8E0>, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff00f2a",
   "metadata": {},
   "source": [
    "28x28 pixel 이미지와 레이블로 구성된 쌍입니다. 이미지는 파이썬 이미징 라이브러리 Pillow의 일부인 'PIL.Image.Image' 클래스의 객체입니다. Python의 데이터 과학을 위한 사실상의 플로팅 및 그래프 라이브러리인 matplotlib를 사용하여 Jupyter 내에서 이미지를 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99de3dda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image, label = dataset[0]\n",
    "plt.imshow(image, cmap='gray')   # plt.axis('off')\n",
    "print('label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc8f5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[10]\n",
    "plt.imshow(image, cmap='gray')   #plt.axis('off')\n",
    "print('label:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06957572",
   "metadata": {},
   "source": [
    "이 이미지는 크기가 상대적으로 작으며 숫자를 인식하는 것은 사람의 눈으로도 때때로 어려울 수 있습니다. 이러한 이미지를 보는 것이 유용하지만 여기에는 한 가지 문제가 있습니다. PyTorch는 이미지로 작업하는 방법을 모릅니다. 이미지를 텐서로 변환해야 합니다. dataset 를 생성하는 동안 변환을 지정하여 이를 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53046a1d",
   "metadata": {},
   "source": [
    "### 짤막한 지식\n",
    "\n",
    "주피터 노트북에서 matplotlib의 imshow가 충돌하여 커널이 강제로 종료되는 경우 다음 해결법이 존재합니다.\n",
    "\n",
    "* 방법 1 <br>\n",
    "　　import os    \n",
    "　　os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "* 방법 2 <br>\n",
    "　　윈도우에서 시스템 환경변수 추가 <br>\n",
    "　　변수: KMP_DUPLICATE_LIB_OK <br>\n",
    "　　값: TRUE\n",
    "\n",
    "* 방법 3 <br>\n",
    "　　conda install nomkl <br>\n",
    "　　주의: 이 경우 다운로드가 불가능할 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20571ab",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0475f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9763a00c",
   "metadata": {},
   "source": [
    "PyTorch dataset를 사용하면 이미지가 로드될 때 이미지에 적용되는 하나 이상의 변환 함수를 지정할 수 있습니다. 'torchvision.transforms' 모듈에는 이러한 미리 정의된 함수들이 많이 포함되어 있습니다. 우리는 'ToTensor' 변환을 사용하여 이미지를 PyTorch 텐서로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8be69254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset (imagse and labels)\n",
    "dataset = MNIST(root='data/', \n",
    "                train=True, \n",
    "                transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c0f4a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "img_tensor, label = dataset[0]\n",
    "print(img_tensor.shape, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d81cba",
   "metadata": {},
   "source": [
    "이제 이미지가 1x28x28 텐서로 변환됩니다. 첫 번째 차원은 색상 채널에 해당합니다. 두 번째 및 세 번째 차원은 각각 이미지의 높이와 너비에 따른 픽셀을 나타냅니다. MNIST 데이터 세트의 이미지는 회색조이므로 채널이 하나만 있습니다. 다른 dataset 에는 색상이 있는 이미지가 있으며 이 경우 빨간색, 녹색 및 파란색(RGB)의 세 가지 채널이 있습니다.\n",
    "\n",
    "텐서 내부의 몇 가지 샘플 값을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2611ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
      "        [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
      "        [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
      "        [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
      "        [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]])\n",
      "tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor[0, 10:15, 10:15])\n",
    "print(torch.max(img_tensor), torch.min(img_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa4ec5d",
   "metadata": {},
   "source": [
    "값의 범위는 0에서 1까지이며, '0'은 검은색, '1'은 흰색, 서로 다른 회색 음영 사이의 값입니다. plt.imshow를 사용하여 텐서를 이미지로 그릴 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6f42f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_tensor[0, 10:15, 10:15], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1545e31",
   "metadata": {},
   "source": [
    "채널 차원 없이 5x5 행렬만 plt.imshow에 전달해야 합니다. 또한 그레이스케일 이미지를 보고 싶다는 것을 나타내기 위해 컬러 맵(cmap=gray)을 전달합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac788e84",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8771ec8b",
   "metadata": {},
   "source": [
    "## Training and Validation Datasets\n",
    "\n",
    "실제 기계 학습 모델을 구축하는 동안 데이터 세트를 세 부분으로 나누는 것이 일반적입니다.\n",
    "\n",
    "1. 훈련(Training) 세트 - 모델을 훈련시키는 데 사용됩니다. 즉, 손실을 계산하고 경사하강법을 사용하여 모델의 가중치를 조정합니다.\n",
    "2. 검증(Validation) 세트 - 훈련 중 모델을 평가하고, 하이퍼파라미터(학습률 등)를 조정하고, 모델의 최상의 버전을 선택하는 데 사용됩니다.\n",
    "3. 테스트(Test) 세트 - 다양한 모델 또는 접근 방식을 비교하고 모델의 최종 정확도를 보고하는 데 사용됩니다.\n",
    "\n",
    "MNIST 데이터셋에는 60,000개의 훈련 이미지와 10,000개의 테스트 이미지가 있습니다. 테스트 세트는 표준화되어 여러 연구자가 동일한 이미지 컬렉션에 대해 모델 결과를 보고할 수 있습니다.\n",
    "\n",
    "사전 정의된 검증 세트가 없기 때문에 60,000개의 이미지를 훈련 및 검증 데이터 세트로 수동으로 분할해야 합니다. 유효성 검사를 위해 무작위로 선택한 10,000개의 이미지를 따로 보관해 보겠습니다. PyTorch의 'random_spilt' 메서드를 사용하여 이 작업을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef0137eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [50000, 10000])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ed10a",
   "metadata": {},
   "source": [
    "검증 세트를 생성하기 위해 무작위 샘플을 선택하는 것은 필수적입니다. 훈련 데이터는 종종 대상 레이블, 즉 0, 1, 2 등의 이미지로 정렬됩니다. 이미지의 마지막 20%를 사용하여 검증 세트를 생성하면 8과 9로만 구성됩니다. 대조적으로 훈련 세트에는 8 또는 9가 포함되지 않습니다. 이러한 훈련 검증은 유용한 모델을 훈련하는 것을 불가능하게 만듭니다.\n",
    "\n",
    "이제 데이터를 일괄적으로 로드하는 데 도움이 되는 데이터 로더를 만들 수 있습니다. 배치 크기 128을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "175485b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d533cb5",
   "metadata": {},
   "source": [
    "각 에포크에서 생성된 배치가 서로 다르게 하기 위해 훈련 데이터 로더에 대해 shuffle=True를 설정했습니다. 이 무작위화는 훈련 과정을 일반화하고 속도를 높이는 데 도움이 됩니다. 반면, validation 데이터 로더는 모델 평가에만 사용되기 때문에 이미지를 섞을 필요가 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc54c5",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "이제 data loader를 준비했으므로 모델을 정의할 수 있습니다.\n",
    "\n",
    "* 로지스틱 회귀 모델은 선형 회귀 모델과 거의 동일합니다. 여기에는 가중치와 편향 행렬이 포함되어 있으며 간단한 행렬 연산(pred = x @ w.t() + b)을 사용하여 출력을 얻습니다.\n",
    "\n",
    "* 선형 회귀에서 했던 것처럼 행렬을 수동으로 생성하고 초기화하는 대신 nn.Linear를 사용하여 모델을 생성할 수 있습니다.\n",
    "\n",
    "* nn.Linear는 각 학습 예제가 벡터가 될 것으로 예상하므로 각 1x28x28 이미지 텐서는 모델에 전달되기 전에 크기 784 (28*28)의 벡터로 flattened 됩니다.\n",
    "\n",
    "* 각 이미지의 출력은 크기가 10인 벡터이며, 각 요소는 특정 대상 레이블(즉, 0에서 9)의 확률을 나타냅니다. 이미지에 대해 예측된 레이블은 단순히 확률이 가장 높은 레이블입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c24bb421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "# Logistic regression model\n",
    "model = nn.Linear(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d54635",
   "metadata": {},
   "source": [
    "물론 이 모델은 매개변수의 수 면에서 이전 모델보다 훨씬 큽니다. 가중치와 편향에 대해 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e022b0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0059,  0.0199,  0.0219,  ..., -0.0304,  0.0045,  0.0357],\n",
       "        [ 0.0181, -0.0044,  0.0218,  ..., -0.0178, -0.0148,  0.0028],\n",
       "        [ 0.0298, -0.0122, -0.0230,  ..., -0.0218,  0.0295, -0.0141],\n",
       "        ...,\n",
       "        [ 0.0195, -0.0275,  0.0263,  ..., -0.0108, -0.0131,  0.0310],\n",
       "        [ 0.0211, -0.0214, -0.0226,  ..., -0.0337, -0.0037,  0.0330],\n",
       "        [-0.0154,  0.0132,  0.0344,  ...,  0.0244, -0.0326, -0.0207]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.weight.shape)\n",
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "523967e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0175, -0.0334,  0.0056,  0.0111, -0.0352, -0.0181,  0.0083,  0.0344,\n",
       "        -0.0287,  0.0265], requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.bias.shape)\n",
    "model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4955be1",
   "metadata": {},
   "source": [
    "여기에는 총 7850개의 매개변수가 있지만 개념적으로는 지금까지 변경된 것이 없습니다. 모델을 사용하여 몇 가지 출력을 생성해 보겠습니다. 데이터 세트에서 첫 번째 배치를 가져와 모델에 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1151944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 2, 9, 8, 1, 3, 1, 7, 1, 4, 2, 4, 5, 1, 3, 2, 0, 7, 0, 9, 1, 7, 0, 4,\n",
      "        1, 7, 1, 9, 7, 5, 5, 1, 0, 7, 1, 3, 7, 1, 9, 6, 6, 8, 8, 3, 1, 9, 1, 6,\n",
      "        6, 2, 3, 5, 9, 8, 0, 6, 4, 9, 5, 3, 6, 2, 7, 7, 0, 9, 1, 9, 8, 9, 1, 8,\n",
      "        0, 4, 8, 6, 8, 3, 5, 4, 8, 4, 6, 4, 9, 4, 6, 3, 1, 2, 0, 1, 1, 6, 1, 5,\n",
      "        7, 3, 2, 9, 6, 1, 7, 8, 9, 1, 8, 8, 6, 7, 7, 6, 2, 2, 5, 2, 9, 3, 8, 1,\n",
      "        7, 7, 7, 3, 8, 7, 8, 5])\n",
      "torch.Size([128, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-d0fe7d306f83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1692\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10)"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    print(outputs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1cb17f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4fc328d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 784])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.reshape(128, 784).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16f87ee",
   "metadata": {},
   "source": [
    "위의 코드는 입력 데이터의 모양이 맞지 않기 때문에 오류가 발생합니다. 우리의 이미지는 1x28x28 모양이지만, 이제는 크기가 784인 벡터가 필요합니다. 즉, flatten 해야 합니다. 우리는 텐서의 .reshape 메소드를 사용할 것입니다. 이를 통해 기본 데이터의 복사본을 실제로 생성하지 않고도 각 이미지를 flat 벡터로 효율적으로 '볼' 수 있습니다. 이 추가 기능을 모델에 포함하려면 PyTorch에서 nn.Module 클래스를 확장하여 사용자 정의 모델을 정의해야 합니다.\n",
    "\n",
    "PyTorch에서 nn.Module 클래스를 확장하여 사용자 정의 모델을 정의해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8821fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a0f78",
   "metadata": {},
   "source": [
    "__init__ 생성자 메서드 내에서 nn.Linear를 사용하여 가중치와 편향을 인스턴스화합니다. 그리고 모델에 일괄 입력을 전달할 때 호출되는 'forward' 메서드 내에서 입력 텐서를 flatten 하여 'self.linear'에 전달합니다.\n",
    "\n",
    "xb.reshape(-1, 28*28)은 2차원의 xb 텐서의 보기를 원한다는 것을 PyTorch에 나타냅니다. 2차원의 길이는 28*28(즉, 784)입니다. .reshape에 대한 하나의 인수는 -1(이 경우 첫 번째 차원)으로 설정하여 PyTorch가 원래 텐서의 모양을 기반으로 자동으로 파악하도록 할 수 있습니다.\n",
    "\n",
    "모델에는 더 이상 .weight 및 .bias 속성이 없지만(이제 .linear 속성 안에 있으므로) 가중치와 편향을 포함하는 목록을 반환하는 .parameters 메서드가 있습니다. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83ccc56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=10, bias=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43af9c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0174, -0.0272,  0.0232,  ..., -0.0180,  0.0002,  0.0193],\n",
       "         [ 0.0140, -0.0036,  0.0187,  ...,  0.0183,  0.0095,  0.0026],\n",
       "         [ 0.0211, -0.0112,  0.0319,  ..., -0.0288, -0.0302, -0.0312],\n",
       "         ...,\n",
       "         [-0.0003,  0.0113,  0.0148,  ..., -0.0064,  0.0346, -0.0012],\n",
       "         [ 0.0146,  0.0300,  0.0328,  ..., -0.0195, -0.0151, -0.0184],\n",
       "         [-0.0225,  0.0067, -0.0220,  ...,  0.0030,  0.0040, -0.0111]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0213, -0.0340, -0.0050,  0.0139, -0.0343, -0.0131,  0.0124, -0.0199,\n",
       "         -0.0289, -0.0184], requires_grad=True)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.linear.weight.shape, model.linear.bias.shape)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba270ea",
   "metadata": {},
   "source": [
    "우리는 이전과 같은 방식으로 새로운 커스텀 모델을 사용할 수 있습니다. 작동하는지 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1b5e443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "outputs.shape: torch.Size([128, 10])\n",
      "sample outputs: \n",
      " tensor([[ 7.5499e-01,  2.4007e-01,  3.0717e-01, -4.8195e-02,  8.5344e-02,\n",
      "          7.8629e-01, -4.4957e-01, -4.9742e-01, -1.4767e-01,  2.6465e-01],\n",
      "        [ 6.7208e-01, -4.8393e-04,  3.7400e-01,  9.2943e-02,  4.4542e-01,\n",
      "          5.3722e-01, -1.5625e-01, -7.7202e-01, -3.3545e-01,  2.2646e-02]])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    break\n",
    "    \n",
    "print(f'outputs.shape: {outputs.shape}')\n",
    "print(f'sample outputs: \\n {outputs[:2].data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d0399d",
   "metadata": {},
   "source": [
    "100개의 입력 이미지 각각에 대해 각 클래스에 대해 하나씩 10개의 출력을 얻습니다. 앞서 논의한 바와 같이 우리는 이러한 출력이 확률을 나타내기를 원합니다. 각 출력 행의 요소는 0에서 1 사이에 있어야 하며 합이 1이 되어야 합니다.\n",
    "\n",
    "출력 행을 확률로 변환하기 위해 다음 공식을 갖는 softmax 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d87ef3e",
   "metadata": {},
   "source": [
    "![소프트맥스](https://i.imgur.com/EAh9jLN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487198f2",
   "metadata": {},
   "source": [
    "먼저 출력 행의 각 요소 yi를 e^yi로 교체하여 모든 요소를 양수로 만듭니다.\n",
    "\n",
    "![](https://www.montereyinstitute.org/courses/DevelopmentalMath/COURSE_TEXT2_RESOURCE/U18_L1_T1_text_final_6_files/image001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b1876",
   "metadata": {},
   "source": [
    "그런 다음 합이 1이 되도록 합으로 나눕니다. 따라서 결과 벡터는 확률로 해석될 수 있습니다.\n",
    "\n",
    "softmax 함수를 구현하는 것은 쉽지만(시도해야 합니다!), 다차원 텐서(이 경우 출력 행 목록)와 잘 작동하는 PyTorch 내에서 제공되는 구현을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b15325ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd16f7d",
   "metadata": {},
   "source": [
    "softmax 함수는 torch.nn.functional 패키지에 포함되어 있으며 함수를 적용해야 하는 차원을 지정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1237ae41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.5499e-01,  2.4007e-01,  3.0717e-01, -4.8195e-02,  8.5344e-02,\n",
       "          7.8629e-01, -4.4957e-01, -4.9742e-01, -1.4767e-01,  2.6465e-01],\n",
       "        [ 6.7208e-01, -4.8393e-04,  3.7400e-01,  9.2943e-02,  4.4542e-01,\n",
       "          5.3722e-01, -1.5625e-01, -7.7202e-01, -3.3545e-01,  2.2646e-02]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea33b670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample probabilities:\n",
      " tensor([[0.1715, 0.1025, 0.1096, 0.0768, 0.0878, 0.1769, 0.0514, 0.0490, 0.0695,\n",
      "         0.1050],\n",
      "        [0.1654, 0.0844, 0.1228, 0.0927, 0.1319, 0.1446, 0.0723, 0.0390, 0.0604,\n",
      "         0.0864]])\n",
      "Sum:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax for each output row\n",
    "probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "# Look at sample probabilities\n",
    "print(\"Sample probabilities:\\n\", probs[:2].data)\n",
    "\n",
    "# Add up the probabilities of an output row\n",
    "print(\"Sum: \", torch.sum(probs[0]).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b2ed66",
   "metadata": {},
   "source": [
    "마지막으로 각 출력 행에서 확률이 가장 높은 요소의 인덱스를 선택하기만 하면 각 이미지에 대한 예측 레이블을 결정할 수 있습니다. 각 행의 가장 큰 요소와 해당 인덱스를 반환하는 torch.max를 사용하여 이를 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e48d46c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 5, 5, 0, 4, 0, 5, 0, 5, 0, 0, 5, 5, 5, 5, 0, 5, 5, 0, 5, 0, 3, 3,\n",
      "        0, 0, 0, 5, 0, 0, 2, 5, 0, 5, 5, 5, 5, 5, 0, 5, 5, 4, 5, 5, 5, 0, 5, 5,\n",
      "        5, 0, 0, 5, 5, 8, 4, 0, 5, 0, 3, 4, 4, 5, 2, 5, 5, 5, 9, 4, 5, 5, 5, 5,\n",
      "        5, 4, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 1, 4, 5, 4, 0, 5,\n",
      "        5, 5, 4, 5, 5, 5, 0, 5, 5, 5, 4, 5, 2, 5, 0, 5, 0, 5, 5, 4, 4, 0, 0, 0,\n",
      "        0, 5, 5, 0, 5, 5, 5, 5])\n",
      "tensor([0.1769, 0.1654, 0.1371, 0.1516, 0.1454, 0.1516, 0.1470, 0.1471, 0.1207,\n",
      "        0.1273, 0.1246, 0.1363, 0.1578, 0.1303, 0.1315, 0.1339, 0.1266, 0.1374,\n",
      "        0.1720, 0.1465, 0.1339, 0.1570, 0.1263, 0.1319, 0.1851, 0.1624, 0.1698,\n",
      "        0.1523, 0.1344, 0.1426, 0.1323, 0.1276, 0.1522, 0.1175, 0.1324, 0.1412,\n",
      "        0.1391, 0.1718, 0.1394, 0.1351, 0.1578, 0.1483, 0.1380, 0.1122, 0.1306,\n",
      "        0.1394, 0.1521, 0.1325, 0.1631, 0.1269, 0.1223, 0.1405, 0.1615, 0.1274,\n",
      "        0.1443, 0.1266, 0.1501, 0.1431, 0.1143, 0.1268, 0.1354, 0.1349, 0.1283,\n",
      "        0.1637, 0.1856, 0.1485, 0.1258, 0.1348, 0.1484, 0.1589, 0.1285, 0.1381,\n",
      "        0.1457, 0.1338, 0.1595, 0.1743, 0.1568, 0.1344, 0.1604, 0.1425, 0.1306,\n",
      "        0.1560, 0.1468, 0.1408, 0.1532, 0.1276, 0.1240, 0.1402, 0.1245, 0.1430,\n",
      "        0.1238, 0.1422, 0.1330, 0.1307, 0.1912, 0.1493, 0.1467, 0.1249, 0.1251,\n",
      "        0.1310, 0.1333, 0.1735, 0.1581, 0.1621, 0.1356, 0.1692, 0.1395, 0.1455,\n",
      "        0.1407, 0.1361, 0.1304, 0.1411, 0.1488, 0.1375, 0.1255, 0.1235, 0.1350,\n",
      "        0.1405, 0.1498, 0.1236, 0.1554, 0.1423, 0.1322, 0.1221, 0.1373, 0.1210,\n",
      "        0.1288, 0.1200], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "max_probs, preds = torch.max(probs, dim=1)\n",
    "print(preds)\n",
    "print(max_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787daa45",
   "metadata": {},
   "source": [
    "위에 인쇄된 숫자는 훈련 이미지의 첫 번째 배치에 대한 예측된 레이블입니다. 실제 라벨과 비교해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "152cdccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 5, 3, 9, 2, 1, 4, 7, 6, 0, 5, 9, 6, 1, 0, 3, 3, 3, 4, 0, 7, 4,\n",
       "        2, 0, 2, 0, 2, 4, 6, 9, 0, 6, 9, 8, 1, 8, 4, 5, 0, 7, 8, 4, 2, 4, 8, 5,\n",
       "        3, 6, 7, 5, 3, 9, 4, 0, 8, 4, 9, 7, 4, 8, 5, 8, 8, 6, 2, 0, 8, 8, 6, 4,\n",
       "        5, 7, 8, 8, 8, 1, 6, 6, 3, 4, 5, 6, 3, 1, 7, 8, 7, 4, 5, 9, 5, 9, 2, 6,\n",
       "        4, 9, 6, 4, 0, 8, 1, 0, 8, 3, 9, 6, 6, 1, 5, 9, 5, 1, 5, 9, 7, 3, 4, 5,\n",
       "        4, 1, 4, 5, 0, 6, 0, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b4081",
   "metadata": {},
   "source": [
    "대부분의 예측된 레이블은 실제 레이블과 다릅니다. 무작위로 초기화된 가중치와 편향으로 시작했기 때문입니다. 모델을 훈련시켜야 합니다. 즉, 더 나은 예측을 위해 경사 하강법을 사용하여 가중치를 조정해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4037987c",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850a887",
   "metadata": {},
   "source": [
    "## Evaluation Metric and Loss Function\n",
    "\n",
    "선형 회귀와 마찬가지로 모델이 얼마나 잘 수행되는지 평가할 방법이 필요합니다. 이를 수행하는 자연스러운 방법은 올바르게 예측된 레이블의 백분율을 찾는 것입니다. 예측의 정확도(accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3f41032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.5499e-01,  2.4007e-01,  3.0717e-01, -4.8195e-02,  8.5344e-02,\n",
       "          7.8629e-01, -4.4957e-01, -4.9742e-01, -1.4767e-01,  2.6465e-01],\n",
       "        [ 6.7208e-01, -4.8393e-04,  3.7400e-01,  9.2943e-02,  4.4542e-01,\n",
       "          5.3722e-01, -1.5625e-01, -7.7202e-01, -3.3545e-01,  2.2646e-02]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad1f04f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(preds == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "202e294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d3568",
   "metadata": {},
   "source": [
    "== 연산자는 모양이 같은 두 텐서의 요소별 비교를 수행하고 같지 않은 요소에 대해 'False'를 포함하고 동일한 요소에 대해 'True'를 포함하는 동일한 모양의 텐서를 반환합니다. 결과를 'torch.sum'에 전달하면 올바르게 예측된 레이블 수를 반환합니다. 마지막으로 정확도를 얻기 위해 총 이미지 수로 나눕니다.\n",
    "\n",
    "결과가 동일한 상대 순서를 가지므로 출력에 softmax를 적용할 필요가 없습니다. 이것은 e^x가 증가하는 함수이기 때문입니다. 즉, y1 > y2이면 e^y1 > e^y2입니다. softmax를 얻기 위해 값을 평균화한 후에도 마찬가지입니다.\n",
    "\n",
    "데이터의 첫 번째 배치에서 현재 모델의 정확도를 계산해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db2b5ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1406)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1b3af3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1715, 0.1025, 0.1096,  ..., 0.0490, 0.0695, 0.1050],\n",
       "        [0.1654, 0.0844, 0.1228,  ..., 0.0390, 0.0604, 0.0864],\n",
       "        [0.1169, 0.0785, 0.1031,  ..., 0.0745, 0.0816, 0.1040],\n",
       "        ...,\n",
       "        [0.1132, 0.0936, 0.1044,  ..., 0.0792, 0.0825, 0.1027],\n",
       "        [0.0884, 0.0848, 0.1053,  ..., 0.0769, 0.0960, 0.1065],\n",
       "        [0.1112, 0.1108, 0.0980,  ..., 0.0889, 0.0976, 0.0912]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2462bb",
   "metadata": {},
   "source": [
    "정확도는 우리(인간)가 모델을 평가하는 훌륭한 방법입니다. 그러나 다음과 같은 이유로 경사하강법을 사용하여 모델을 최적화하기 위한 손실 함수로 사용할 수 없습니다.\n",
    "\n",
    "1. 미분이 가능하지 않습니다. torch.max와 ==는 모두 비연속적이며 미분할 수 없는 연산이므로 가중치와 편향으로 기울기를 계산하는 데 정확도를 사용할 수 없습니다.\n",
    "\n",
    "2. 모델에서 예측한 실제 확률을 고려하지 않으므로 점진적 개선에 대한 충분한 피드백을 제공할 수 없습니다.\n",
    "\n",
    "이러한 이유로 정확도는 종종 분류를 위한 평가 메트릭(evaluation metric) 으로 사용되지만 손실 함수로는 사용되지 않습니다. 분류 문제에 일반적으로 사용되는 손실 함수는 교차 엔트로피(cross-entropy)이며 다음 공식을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5721230",
   "metadata": {},
   "source": [
    "![크로스 엔트로피](https://i.imgur.com/VDRDl1D.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b94ccb",
   "metadata": {},
   "source": [
    "복잡해 보이지만 실제로는 매우 간단합니다.\n",
    "\n",
    "각 출력 행에 대해 올바른 레이블에 대한 예측 확률을 선택합니다. 위의 그림에서, 이미지에 대한 예측 확률이 '[0.1, 0.5, 0.4]'이고 올바른 레이블이 '1'이면 해당 요소 '0.5'을 선택하고 나머지는 무시합니다.\n",
    "\n",
    "그런 다음 선택한 확률의 logarithm을 취합니다. 확률이 높으면, 즉 1에 가까우면 그 로그는 0에 가까운 매우 작은 음수 값입니다. 그리고 확률이 낮으면(0에 가까움) 로그는 매우 큰 음수 값입니다. 또한 결과에 -1을 곱합니다. 이는 결과가 좋지 않은 예측에 대한 손실의 큰 양수 값입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e3773f",
   "metadata": {},
   "source": [
    "![](https://www.intmath.com/blog/wp-content/images/2019/05/log10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b3bcab",
   "metadata": {},
   "source": [
    "마지막으로 모든 출력 행에 대한 교차 엔트로피의 평균을 취하여 데이터 배치에 대한 전체 손실을 얻습니다.\n",
    "\n",
    "정확도와 달리 교차 엔트로피는 연속적이고 미분 가능한 함수입니다. 또한 모델의 점진적 개선에 대한 유용한 피드백을 제공합니다(정확한 레이블에 대한 약간 더 높은 확률은 더 낮은 손실로 이어짐). 이 두 가지 요소는 교차 엔트로피를 손실 함수에 더 나은 선택으로 만듭니다.\n",
    "\n",
    "예상할 수 있듯이 PyTorch는 torch.nn.functional 패키지의 일부로 효율적이고 텐서 친화적인 cross-entropy 구현을 제공합니다. 또한 내부적으로 softmax를 수행하므로 확률로 변환하지 않고 모델의 출력을 직접 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e1d101b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.5499e-01,  2.4007e-01,  3.0717e-01,  ..., -4.9742e-01,\n",
       "         -1.4767e-01,  2.6465e-01],\n",
       "        [ 6.7208e-01, -4.8393e-04,  3.7400e-01,  ..., -7.7202e-01,\n",
       "         -3.3545e-01,  2.2646e-02],\n",
       "        [ 3.2241e-01, -7.6278e-02,  1.9631e-01,  ..., -1.2818e-01,\n",
       "         -3.7615e-02,  2.0562e-01],\n",
       "        ...,\n",
       "        [ 1.9773e-01,  8.0306e-03,  1.1750e-01,  ..., -1.5883e-01,\n",
       "         -1.1808e-01,  1.0046e-01],\n",
       "        [-3.4999e-02, -7.6971e-02,  1.4011e-01,  ..., -1.7402e-01,\n",
       "          4.7888e-02,  1.5116e-01],\n",
       "        [ 8.6415e-02,  8.3145e-02, -3.9704e-02,  ..., -1.3699e-01,\n",
       "         -4.4149e-02, -1.1149e-01]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f696416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19874ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2864, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Loss for current batch of data\n",
    "loss = loss_fn(outputs, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9195d05f",
   "metadata": {},
   "source": [
    "우리는 cross-entropy 가 모든 훈련 샘플에 대해 평균화된 올바른 레이블의 예측 확률의 음의 로그라는 것을 알고 있습니다. 따라서 결과 숫자를 해석하는 한 가지 방법은 다음과 같습니다. \n",
    "\n",
    "결과값 2.28은 올바른 레이블의 예측 확률로써 e^-2.28, 즉 0.1 정도입니다. 손실이 낮을수록 좋은 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4e4895",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c26f4da",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a209e29",
   "metadata": {},
   "source": [
    "이제 데이터 로더, 모델, 손실 함수 및 옵티마이저를 정의했으므로 모델을 훈련할 준비가 되었습니다. 훈련 과정은 각 시대의 모델을 평가하기 위해 \"검증 단계\"가 추가된 선형 회귀와 동일합니다. pseudocode는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac64218",
   "metadata": {},
   "source": [
    "```\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    for batch in train_loader:\n",
    "        # Generate predictions\n",
    "        # Calculate loss\n",
    "        # Compute gradients\n",
    "        # Update weights\n",
    "        # Reset gradients\n",
    "    \n",
    "    # Validation phase\n",
    "    for batch in val_loader:\n",
    "        # Generate predictions\n",
    "        # Calculate loss\n",
    "        # Calculate metrics (accuracy etc.)\n",
    "    # Calculate average validation loss & metrics\n",
    "    \n",
    "    # Log epoch, loss & metrics for inspection\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891ce79",
   "metadata": {},
   "source": [
    "훈련 루프의 일부는 우리가 해결하고 있는 특정 문제(예: 손실 함수, 메트릭 등)에 특정한 반면 다른 부분은 일반적이며 모든 딥러닝 문제에 적용할 수 있습니다.\n",
    "\n",
    "모델을 훈련하는 데 사용되는 'fit'이라는 함수에 문제와 무관한 부분을 포함할 것입니다. 문제별 부분은 `nn.Module` 클래스에 새 메서드를 추가하여 구현됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e166b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    history = [] # for recording epoch-wise results\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Training phase\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10861847",
   "metadata": {},
   "source": [
    "'fit' 함수는 각 에포크의 유효성 검사 손실과 메트릭을 기록합니다. 디버깅 및 시각화에 유용한 교육 기록을 반환합니다.\n",
    "\n",
    "배치 크기, 학습률 등과 같은 구성(초매개변수라고 함)은 기계 학습 모델을 학습하는 동안 미리 선택해야 합니다. 적절한 초매개변수를 선택하는 것은 합리적인 시간 내에 합리적으로 정확한 모델을 훈련하는 데 중요합니다. 기계 학습에서 연구 및 실험이 활발한 영역입니다. 자유롭게 다양한 학습률을 시도하고 학습 과정에 어떤 영향을 미치는지 확인하십시오.\n",
    "\n",
    "'fit'의 검증 단계에서 사용되는 'evaluate' 함수를 정의해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb9bade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e3f3d9",
   "metadata": {},
   "source": [
    "마지막으로 fit과 evaluate에서 사용하는 training_step, validation_step, validation_epoch_end, epoch_end를 추가로 포함하도록 MnistModel 클래스를 재정의해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bda1a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "    \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b7122",
   "metadata": {},
   "source": [
    "모델을 훈련하기 전에 무작위로 초기화된 가중치 및 편향의 초기 세트를 사용하여 검증 세트에서 모델이 어떻게 수행되는지 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96be9397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.329630136489868, 'val_acc': 0.05448971688747406}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0 = evaluate(model, val_loader)\n",
    "result0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f9d6d",
   "metadata": {},
   "source": [
    "초기 정확도는 약 10%이며 무작위로 초기화된 모델에서 기대할 수 있습니다(무작위로 추측하여 올바른 레이블을 얻을 확률이 10분의 1이기 때문에).\n",
    "\n",
    "이제 모델을 훈련할 준비가 되었습니다. 5개의 Epoch 동안 훈련하고 결과를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4331cbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.9635, val_acc: 0.5978\n",
      "Epoch [1], val_loss: 1.6918, val_acc: 0.7204\n",
      "Epoch [2], val_loss: 1.4888, val_acc: 0.7571\n",
      "Epoch [3], val_loss: 1.3355, val_acc: 0.7775\n",
      "Epoch [4], val_loss: 1.2175, val_acc: 0.7909\n"
     ]
    }
   ],
   "source": [
    "history1 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d2e80",
   "metadata": {},
   "source": [
    "좋은 결과입니다! 단 5개의 Epoch 훈련으로 우리 모델은 검증 세트에서 80% 이상의 정확도에 도달했습니다. 몇 에포크(epoch)에 대한 훈련을 더 개선할 수 있는지 봅시다. 아래의 각 셀에서 학습률과 Epoch 수를 변경해 보십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "890327c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.1247, val_acc: 0.8030\n",
      "Epoch [1], val_loss: 1.0502, val_acc: 0.8104\n",
      "Epoch [2], val_loss: 0.9893, val_acc: 0.8147\n",
      "Epoch [3], val_loss: 0.9385, val_acc: 0.8204\n",
      "Epoch [4], val_loss: 0.8956, val_acc: 0.8248\n"
     ]
    }
   ],
   "source": [
    "history2 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c54ff695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.8589, val_acc: 0.8287\n",
      "Epoch [1], val_loss: 0.8270, val_acc: 0.8316\n",
      "Epoch [2], val_loss: 0.7991, val_acc: 0.8333\n",
      "Epoch [3], val_loss: 0.7745, val_acc: 0.8357\n",
      "Epoch [4], val_loss: 0.7526, val_acc: 0.8381\n"
     ]
    }
   ],
   "source": [
    "history3 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11550ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.7329, val_acc: 0.8411\n",
      "Epoch [1], val_loss: 0.7151, val_acc: 0.8434\n",
      "Epoch [2], val_loss: 0.6990, val_acc: 0.8450\n",
      "Epoch [3], val_loss: 0.6843, val_acc: 0.8470\n",
      "Epoch [4], val_loss: 0.6708, val_acc: 0.8490\n"
     ]
    }
   ],
   "source": [
    "history4 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1c3d60",
   "metadata": {},
   "source": [
    "더 많은 Epoch에 대해 학습함에 따라 정확도는 계속 증가하지만 개선은 모든 Epoch에 따라 작아집니다. 이것을 선 그래프를 사용하여 시각화해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f06d8061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = [result0] + history1 + history2 + history3 + history4\n",
    "accuracies = [result['val_acc'] for result in history]\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf6c5e",
   "metadata": {},
   "source": [
    "위의 그림을 보면 아주 오랜 시간 동안 훈련을 시켜도 모델이 정확도 임계값 90%를 넘지 않을 것이라는 점을 아주 분명하게 알 수 있습니다. 이에 대한 한 가지 가능한 이유는 학습률이 너무 높을 수 있기 때문입니다. 모델의 매개변수는 가장 낮은 손실을 위한 최적의 매개변수 세트를 중심으로 \"바운스\"할 수 있습니다. 학습 속도를 줄이고 몇 에포크를 더 훈련하여 도움이 되는지 확인할 수 있습니다.\n",
    "\n",
    "모델이 충분히 강력하지 않은 이유가 더 많습니다. 우리는 출력(이 경우 클래스 확률)이 가중치 행렬로 행렬 곱셈을 수행하고 편향을 추가하여 얻은 입력(픽셀 강도)의 선형 함수라고 가정했습니다. 이것은 이미지의 픽셀 강도와 이미지가 나타내는 숫자 사이에 선형 관계가 실제로 존재하지 않을 수 있으므로 이것은 상당히 약한 가정입니다. MNIST와 같은 간단한 데이터 세트에서는 합리적으로 잘 작동하지만(85% 정확도 제공), 일상적인 물체, 동물 등을 인식하는 것과 같은 복잡한 작업을 위해 이미지 픽셀과 레이블 간의 비선형 관계를 캡처할 수 있는 보다 정교한 모델이 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386241e",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac92804",
   "metadata": {},
   "source": [
    "## Testing with individual images\n",
    "\n",
    "지금까지 모델의 전체 정확도를 추적했지만 일부 샘플 이미지에서 모델의 결과를 살펴보는 것도 좋은 생각입니다. 미리 정의된 10000개 이미지의 테스트 데이터 세트에서 일부 이미지로 모델을 테스트해 보겠습니다. 먼저 'ToTensor' 변환으로 테스트 데이터 세트를 다시 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "486d2bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test dataset\n",
    "test_dataset = MNIST(root='data/', \n",
    "                     train=False,\n",
    "                     transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f53579",
   "metadata": {},
   "source": [
    "다음은 데이터세트의 샘플 이미지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea0c805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([1, 28, 28])\n",
      "Label: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Shape:', img.shape)\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d9beb",
   "metadata": {},
   "source": [
    "단일 이미지 텐서에 대해 예측된 레이블을 반환하는 도우미 함수 predict_image를 정의해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38536e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dfc812",
   "metadata": {},
   "source": [
    "img.unsqueeze는 1x28x28 텐서의 시작 부분에 다른 차원을 추가하여 1x1x28x28 텐서로 만들고 모델이 단일 이미지를 포함하는 배치로 봅니다.\n",
    "\n",
    "몇 가지 이미지로 시도해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8d37c22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7 , Predicted: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAM4ElEQVR4nO3db6xU9Z3H8c9nWZoY6QNQce9alC7xgc3GgCIxQTfXkDYsPsBGuikPGjZpvH2Apo0NWeM+wIeN2bZZn5DcRlO6YW1IqEqMcSHYSBq18WJQLr0BkbBwyxVsMCmYGES/++AeN1ecc2acMzNn4Pt+JZOZOd85Z74Z7odz5vyZnyNCAK5+f9N0AwAGg7ADSRB2IAnCDiRB2IEk/naQb2abXf9An0WEW02vtWa3vdb2EdvHbD9WZ1kA+svdHme3PU/SUUnfljQt6U1JGyPiTxXzsGYH+qwfa/ZVko5FxPGIuCjpt5LW11gegD6qE/abJJ2a83y6mPYFtsdsT9ieqPFeAGqqs4Ou1abClzbTI2Jc0rjEZjzQpDpr9mlJS+Y8/4ak0/XaAdAvdcL+pqRbbX/T9tckfV/S7t60BaDXut6Mj4hLth+W9D+S5kl6JiIO96wzAD3V9aG3rt6M7+xA3/XlpBoAVw7CDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJdj88uSbZPSDov6VNJlyJiZS+aAtB7tcJeuC8i/tKD5QDoIzbjgSTqhj0k7bF9wPZYqxfYHrM9YXui5nsBqMER0f3M9t9HxGnbiyXtlfRIROyveH33bwagIxHhVtNrrdkj4nRxf1bSc5JW1VkegP7pOuy2r7X99c8fS/qOpMleNQagt+rsjb9R0nO2P1/Of0fEyz3pCkDP1frO/pXfjO/sQN/15Ts7gCsHYQeSIOxAEoQdSIKwA0n04kKYFDZs2FBae+ihhyrnPX36dGX9448/rqzv2LGjsv7++++X1o4dO1Y5L/JgzQ4kQdiBJAg7kARhB5Ig7EAShB1IgrADSXDVW4eOHz9eWlu6dOngGmnh/PnzpbXDhw8PsJPhMj09XVp78sknK+edmLhyf0WNq96A5Ag7kARhB5Ig7EAShB1IgrADSRB2IAmuZ+9Q1TXrt99+e+W8U1NTlfXbbrutsn7HHXdU1kdHR0trd999d+W8p06dqqwvWbKksl7HpUuXKusffPBBZX1kZKTr9z558mRl/Uo+zl6GNTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMH17FeBhQsXltaWL19eOe+BAwcq63fddVc3LXWk3e/lHz16tLLe7vyFRYsWldY2b95cOe+2bdsq68Os6+vZbT9j+6ztyTnTFtnea/vd4r78rw3AUOhkM/7XktZeNu0xSfsi4lZJ+4rnAIZY27BHxH5J5y6bvF7S9uLxdkkP9LYtAL3W7bnxN0bEjCRFxIztxWUvtD0maazL9wHQI32/ECYixiWNS+ygA5rU7aG3M7ZHJKm4P9u7lgD0Q7dh3y1pU/F4k6QXetMOgH5pe5zd9rOSRiVdL+mMpK2Snpe0U9LNkk5K+l5EXL4Tr9Wy2IxHxx588MHK+s6dOyvrk5OTpbX77ruvct5z59r+OQ+tsuPsbb+zR8TGktKaWh0BGChOlwWSIOxAEoQdSIKwA0kQdiAJLnFFYxYvLj3LWpJ06NChWvNv2LChtLZr167Kea9kDNkMJEfYgSQIO5AEYQeSIOxAEoQdSIKwA0kwZDMa0+7nnG+44YbK+ocfflhZP3LkyFfu6WrGmh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuB6dvTV6tWrS2uvvPJK5bzz58+vrI+OjlbW9+/fX1m/WnE9O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kwfXs6Kt169aV1todR9+3b19l/fXXX++qp6zartltP2P7rO3JOdOesP1n2weLW/m/KICh0Mlm/K8lrW0x/ZcRsby4vdTbtgD0WtuwR8R+SecG0AuAPqqzg+5h2+8Um/kLy15ke8z2hO2JGu8FoKZuw75N0jJJyyXNSPp52QsjYjwiVkbEyi7fC0APdBX2iDgTEZ9GxGeSfiVpVW/bAtBrXYXd9sicp9+VNFn2WgDDoe1xdtvPShqVdL3taUlbJY3aXi4pJJ2Q9KP+tYhhds0111TW165tdSBn1sWLFyvn3bp1a2X9k08+qazji9qGPSI2tpj8dB96AdBHnC4LJEHYgSQIO5AEYQeSIOxAElziilq2bNlSWV+xYkVp7eWXX66c97XXXuuqJ7TGmh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmDIZlS6//77K+vPP/98Zf2jjz4qrVVd/ipJb7zxRmUdrTFkM5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kwfXsyV133XWV9aeeeqqyPm/evMr6Sy+Vj/nJcfTBYs0OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwPftVrt1x8HbHuu+8887K+nvvvVdZr7pmvd286E7X17PbXmL797anbB+2/eNi+iLbe22/W9wv7HXTAHqnk834S5J+GhG3Sbpb0mbb35L0mKR9EXGrpH3FcwBDqm3YI2ImIt4qHp+XNCXpJknrJW0vXrZd0gN96hFAD3ylc+NtL5W0QtIfJd0YETPS7H8ItheXzDMmaaxmnwBq6jjsthdI2iXpJxHxV7vlPoAviYhxSePFMthBBzSko0NvtudrNug7IuJ3xeQztkeK+oiks/1pEUAvtF2ze3YV/rSkqYj4xZzSbkmbJP2suH+hLx2ilmXLllXW2x1aa+fRRx+trHN4bXh0shm/WtIPJB2yfbCY9rhmQ77T9g8lnZT0vb50CKAn2oY9Iv4gqewL+pretgOgXzhdFkiCsANJEHYgCcIOJEHYgST4KemrwC233FJa27NnT61lb9mypbL+4osv1lo+Boc1O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXH2q8DYWPmvft188821lv3qq69W1gf5U+SohzU7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBcfYrwD333FNZf+SRRwbUCa5krNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IIlOxmdfIuk3kv5O0meSxiPiP20/IekhSR8UL308Il7qV6OZ3XvvvZX1BQsWdL3sduOnX7hwoetlY7h0clLNJUk/jYi3bH9d0gHbe4vaLyPiP/rXHoBe6WR89hlJM8Xj87anJN3U78YA9NZX+s5ue6mkFZL+WEx62PY7tp+xvbBknjHbE7Yn6rUKoI6Ow257gaRdkn4SEX+VtE3SMknLNbvm/3mr+SJiPCJWRsTK+u0C6FZHYbc9X7NB3xERv5OkiDgTEZ9GxGeSfiVpVf/aBFBX27DbtqSnJU1FxC/mTB+Z87LvSprsfXsAeqWTvfGrJf1A0iHbB4tpj0vaaHu5pJB0QtKP+tAfanr77bcr62vWrKmsnzt3rpftoEGd7I3/gyS3KHFMHbiCcAYdkARhB5Ig7EAShB1IgrADSRB2IAkPcshd24zvC/RZRLQ6VM6aHciCsANJEHYgCcIOJEHYgSQIO5AEYQeSGPSQzX+R9L9znl9fTBtGw9rbsPYl0Vu3etnbLWWFgZ5U86U3tyeG9bfphrW3Ye1LorduDao3NuOBJAg7kETTYR9v+P2rDGtvw9qXRG/dGkhvjX5nBzA4Ta/ZAQwIYQeSaCTsttfaPmL7mO3HmuihjO0Ttg/ZPtj0+HTFGHpnbU/OmbbI9l7b7xb3LcfYa6i3J2z/ufjsDtpe11BvS2z/3vaU7cO2f1xMb/Szq+hrIJ/bwL+z254n6aikb0ualvSmpI0R8aeBNlLC9glJKyOi8RMwbP+TpAuSfhMR/1hMe1LSuYj4WfEf5cKI+Lch6e0JSReaHsa7GK1oZO4w45IekPSvavCzq+jrXzSAz62JNfsqScci4nhEXJT0W0nrG+hj6EXEfkmXD8myXtL24vF2zf6xDFxJb0MhImYi4q3i8XlJnw8z3uhnV9HXQDQR9psknZrzfFrDNd57SNpj+4DtsaabaeHGiJiRZv94JC1uuJ/LtR3Ge5AuG2Z8aD67boY/r6uJsLf6faxhOv63OiLukPTPkjYXm6voTEfDeA9Ki2HGh0K3w5/X1UTYpyUtmfP8G5JON9BHSxFxurg/K+k5Dd9Q1Gc+H0G3uD/bcD//b5iG8W41zLiG4LNrcvjzJsL+pqRbbX/T9tckfV/S7gb6+BLb1xY7TmT7Wknf0fANRb1b0qbi8SZJLzTYyxcMyzDeZcOMq+HPrvHhzyNi4DdJ6zS7R/49Sf/eRA8lff2DpLeL2+Gme5P0rGY36z7R7BbRDyVdJ2mfpHeL+0VD1Nt/STok6R3NBmukod7u0exXw3ckHSxu65r+7Cr6GsjnxumyQBKcQQckQdiBJAg7kARhB5Ig7EAShB1IgrADSfwfrLwRQB25h+kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9b416c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0 , Predicted: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[10]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f92fd117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 9 , Predicted: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[193]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ba0b287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2 , Predicted: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[1839]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06384572",
   "metadata": {},
   "source": [
    "모델 성능이 저조한 위치를 식별하면 더 많은 훈련 데이터를 수집하고 모델의 복잡성을 증가/감소시키고 하이퍼파라미터를 변경하여 모델을 개선하는 데 도움이 될 수 있습니다.\n",
    "\n",
    "마지막 단계로 테스트 세트에서 모델의 전체 손실과 정확도도 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4289bf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.6435350179672241, 'val_acc': 0.859375}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "result = evaluate(model, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be81e912",
   "metadata": {},
   "source": [
    "우리는 이것이 검증 세트의 정확도/손실과 유사할 것으로 예상합니다. 그렇지 않은 경우 테스트 세트와 유사한 데이터 및 분포를 가진 더 나은 검증 세트가 필요할 수 있습니다(종종 실제 데이터에서 가져옴)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb97c1d7",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab0e1c",
   "metadata": {},
   "source": [
    "## Saving and loading the model\n",
    "\n",
    "우리는 오랜 시간 동안 모델을 훈련했고 상당한 정확도를 달성했기 때문에 나중에 모델을 재사용하고 처음부터 다시 훈련하지 않도록 가중치와 편향 행렬을 디스크에 저장하는 것이 좋습니다. 모델을 저장하는 방법은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c2e219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mnist-logistic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ce9c3aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0229, -0.0214,  0.0087,  ..., -0.0293,  0.0171,  0.0110],\n",
       "                      [ 0.0095, -0.0292, -0.0240,  ..., -0.0354,  0.0327, -0.0101],\n",
       "                      [-0.0136,  0.0133,  0.0085,  ...,  0.0347, -0.0174,  0.0213],\n",
       "                      ...,\n",
       "                      [ 0.0287, -0.0119, -0.0014,  ...,  0.0207,  0.0164, -0.0072],\n",
       "                      [ 0.0152,  0.0131,  0.0351,  ..., -0.0329, -0.0220, -0.0044],\n",
       "                      [-0.0035, -0.0262, -0.0004,  ..., -0.0115, -0.0193,  0.0095]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0571,  0.0816, -0.0078, -0.0464,  0.0073,  0.0774, -0.0338,  0.0699,\n",
       "                      -0.0943, -0.0400]))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c8670",
   "metadata": {},
   "source": [
    "모델 가중치를 로드하기 위해 MnistModel 클래스의 새 객체를 인스턴스화하고 .load_state_dict 메소드를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "08e12f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "760fa779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[-0.0002,  0.0211,  0.0090,  ..., -0.0048, -0.0349,  0.0164],\n",
       "                      [-0.0039,  0.0321,  0.0019,  ...,  0.0340,  0.0330, -0.0120],\n",
       "                      [-0.0312,  0.0311, -0.0155,  ...,  0.0196, -0.0301, -0.0263],\n",
       "                      ...,\n",
       "                      [-0.0209, -0.0340, -0.0046,  ..., -0.0177, -0.0196, -0.0239],\n",
       "                      [-0.0076, -0.0245,  0.0063,  ..., -0.0175, -0.0002,  0.0212],\n",
       "                      [-0.0127,  0.0348,  0.0098,  ...,  0.0052,  0.0341,  0.0087]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0187, -0.0051,  0.0150,  0.0187, -0.0229, -0.0166,  0.0228,  0.0142,\n",
       "                       0.0265,  0.0079]))])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9dc7934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.3253676891326904, 'val_acc': 0.14248046278953552}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "result = evaluate(model2, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "61b17825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0229, -0.0214,  0.0087,  ..., -0.0293,  0.0171,  0.0110],\n",
       "                      [ 0.0095, -0.0292, -0.0240,  ..., -0.0354,  0.0327, -0.0101],\n",
       "                      [-0.0136,  0.0133,  0.0085,  ...,  0.0347, -0.0174,  0.0213],\n",
       "                      ...,\n",
       "                      [ 0.0287, -0.0119, -0.0014,  ...,  0.0207,  0.0164, -0.0072],\n",
       "                      [ 0.0152,  0.0131,  0.0351,  ..., -0.0329, -0.0220, -0.0044],\n",
       "                      [-0.0035, -0.0262, -0.0004,  ..., -0.0115, -0.0193,  0.0095]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0571,  0.0816, -0.0078, -0.0464,  0.0073,  0.0774, -0.0338,  0.0699,\n",
       "                      -0.0943, -0.0400]))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load('mnist-logistic.pth'))\n",
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37476e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.6435350179672241, 'val_acc': 0.859375}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "result = evaluate(model2, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4ecb6",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883677f1",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "지금까지 배운 개념과 기술을 적용하기 위해 다음 문제를 가지고 연습해 보세요:\n",
    "\n",
    "* End-to-end 모델 코딩을 위한 연습 노트: https://jovian.ai/aakashns/02-insurance-linear-regression\n",
    "* 로지스틱 회귀 분석 프로젝트를 위한 시작 노트: https://jovian.ai/aakashns/mnist-logistic-minimal\n",
    "* 선형 회귀 프로젝트를 위한 시작 노트: https://jovian.ai/aakashns/housing-linear-minimal\n",
    "\n",
    "짧은 시간 내에 훌륭한 기계 학습 모델을 훈련하려면 연습과 경험이 필요합니다. 다양한 데이터 세트, 모델 및 하이퍼 파라미터로 실험해 보십시오. 이 기술을 습득하는 가장 좋은 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1f8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
